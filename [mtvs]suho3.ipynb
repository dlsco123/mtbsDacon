{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install xgboost\n",
    "#%pip install wordcloud\n",
    "#%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "## for data\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk## for language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>Phil A. St. Amant</td>\n",
       "      <td>Herman A. Thompson</td>\n",
       "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Stephen Duncan</td>\n",
       "      <td>Lawrence Owens</td>\n",
       "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>Billy Joe Magwood</td>\n",
       "      <td>Tony Patterson, Warden, et al.</td>\n",
       "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Linkletter</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Victor Linkletter was convicted in state court...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>William Earl Fikes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID         first_party                    second_party  \\\n",
       "0  TRAIN_0000   Phil A. St. Amant              Herman A. Thompson   \n",
       "1  TRAIN_0001      Stephen Duncan                  Lawrence Owens   \n",
       "2  TRAIN_0002   Billy Joe Magwood  Tony Patterson, Warden, et al.   \n",
       "3  TRAIN_0003          Linkletter                          Walker   \n",
       "4  TRAIN_0004  William Earl Fikes                         Alabama   \n",
       "\n",
       "                                               facts  first_party_winner  \n",
       "0  On June 27, 1962, Phil St. Amant, a candidate ...                   1  \n",
       "1  Ramon Nelson was riding his bike when he suffe...                   0  \n",
       "2  An Alabama state court convicted Billy Joe Mag...                   1  \n",
       "3  Victor Linkletter was convicted in state court...                   0  \n",
       "4  On April 24, 1953 in Selma, Alabama, an intrud...                   1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('c:/data/project/train.csv')\n",
    "test = pd.read_csv('c:/data/project/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train[['facts', 'first_party_winner']]\n",
    "df_target = df[['first_party_winner']]\n",
    "df_nlp = df[['facts']]\n",
    "df_nlp1 = pd.DataFrame(df_nlp, columns=['facts'])\n",
    "df_nlp1['facts'] = df_nlp1['facts'].str.replace(r'<[^<>]*>', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_nlp1['facts']\n",
    "# print(corpus.str.cat(sep=\" \")) # 인덱스의 요소들 서로 잇기\n",
    "lst_tokens = nltk.tokenize.word_tokenize(corpus.str.cat(sep=\" \"))\n",
    "ps = nltk.stem.porter.PorterStemmer()\n",
    "lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "lst_stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 깨끗하게 만드는 함수\n",
    "\n",
    "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    import re\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list # 역토큰화, TF-IDF를 사용하기 위해서\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facts_clean</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>june 27 1962 phil st amant candidate public of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ramon nelson riding bike suffered lethal blow ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alabama state court convicted billy joe magwoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>victor linkletter convicted state court eviden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>april 24 1953 selma alabama intruder broke apa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>congress amended clean air act energy policy a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>alliance bond fund inc investment fund purchas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>1992 district court sentenced manuel peguero 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>march 8 1996 enrico st cyr lawful permanent re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>herbert markman owns patent system track cloth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            facts_clean  first_party_winner\n",
       "0     june 27 1962 phil st amant candidate public of...                   1\n",
       "1     ramon nelson riding bike suffered lethal blow ...                   0\n",
       "2     alabama state court convicted billy joe magwoo...                   1\n",
       "3     victor linkletter convicted state court eviden...                   0\n",
       "4     april 24 1953 selma alabama intruder broke apa...                   1\n",
       "...                                                 ...                 ...\n",
       "2473  congress amended clean air act energy policy a...                   1\n",
       "2474  alliance bond fund inc investment fund purchas...                   1\n",
       "2475  1992 district court sentenced manuel peguero 2...                   0\n",
       "2476  march 8 1996 enrico st cyr lawful permanent re...                   0\n",
       "2477  herbert markman owns patent system track cloth...                   0\n",
       "\n",
       "[2478 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 깨끗하게 만드는 함수 사용\n",
    "df_nlp1[\"facts_clean\"] = df_nlp1[\"facts\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=lst_stopwords))\n",
    "\n",
    "# y값 포함해서 하나의 프레임으로 만들기\n",
    "df_nlp2 = pd.concat([df_nlp1,df_target['first_party_winner']],axis=1, join='inner')\n",
    "df_nlp2 = df_nlp2.drop(columns='facts')\n",
    "df_nlp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>011119</th>\n",
       "      <th>0125</th>\n",
       "      <th>02</th>\n",
       "      <th>036539</th>\n",
       "      <th>04</th>\n",
       "      <th>041352</th>\n",
       "      <th>041581</th>\n",
       "      <th>0479</th>\n",
       "      <th>05</th>\n",
       "      <th>0511287</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoned</th>\n",
       "      <th>zoneofinterests</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zubik</th>\n",
       "      <th>zuni</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zurko</th>\n",
       "      <th>zurkos</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 17810 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      011119  0125   02  036539   04  041352  041581  0479   05  0511287  ...  \\\n",
       "0        0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "1        0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "2        0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "3        0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "4        0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "...      ...   ...  ...     ...  ...     ...     ...   ...  ...      ...  ...   \n",
       "2473     0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "2474     0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "2475     0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "2476     0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "2477     0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "\n",
       "      zone  zoned  zoneofinterests  zoning  zubik  zuni  zurich  zurko  \\\n",
       "0      0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "1      0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "2      0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "3      0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "4      0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "...    ...    ...              ...     ...    ...   ...     ...    ...   \n",
       "2473   0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "2474   0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "2475   0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "2476   0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "2477   0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "\n",
       "      zurkos  first_party_winner  \n",
       "0        0.0                   1  \n",
       "1        0.0                   0  \n",
       "2        0.0                   1  \n",
       "3        0.0                   0  \n",
       "4        0.0                   1  \n",
       "...      ...                 ...  \n",
       "2473     0.0                   1  \n",
       "2474     0.0                   1  \n",
       "2475     0.0                   0  \n",
       "2476     0.0                   0  \n",
       "2477     0.0                   0  \n",
       "\n",
       "[2478 rows x 17810 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TFIDF 적용, 문서들의 유사도를 구하는 작업\n",
    "\n",
    "vectorizeTF = TfidfVectorizer(stop_words='english')\n",
    "count_matrix_tf = vectorizeTF.fit_transform(df_nlp2['facts_clean'])\n",
    "data_final = count_matrix_tf.toarray()\n",
    "data_final = pd.DataFrame(data=data_final, columns=vectorizeTF.get_feature_names_out())\n",
    "data_final = pd.concat([data_final,df_nlp2[\"first_party_winner\"]],axis=1,join='inner')\n",
    "data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카운터 벡터라이즈는 사용중단\n",
    "# vectorize=CountVectorizer()\n",
    "# count_matrix = vectorize.fit_transform(df_nlp2['facts_clean'])\n",
    "# count_array = count_matrix.toarray()\n",
    "# data_final = pd.DataFrame(data=count_array,columns = vectorize.get_feature_names_out())\n",
    "# data_final = pd.concat([data_final,df_nlp2[\"first_party_winner\"]],axis=1,join='inner')\n",
    "# data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_final.drop(columns=['first_party_winner']), data_final['first_party_winner'], test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA 학습, 단어의 의미구조 파악\n",
    "# 30초정도 걸림\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=200, random_state=1) # n_component : 토픽 갯수\n",
    "lda_data = lda.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('sale', 1.64), ('abortion', 1.55), ('minor', 1.07), ('parent', 0.97), ('notification', 0.81)]\n",
      "Topic 2: [('applicable', 1.32), ('motor', 1.21), ('initially', 1.01), ('arbitrator', 0.88), ('investment', 0.83)]\n",
      "Topic 3: [('film', 0.73), ('fsa', 0.66), ('obscene', 0.65), ('eberhart', 0.47), ('athlete', 0.45)]\n",
      "Topic 4: [('registration', 0.95), ('rodgers', 0.79), ('beaudreaux', 0.72), ('rippo', 0.69), ('discon', 0.61)]\n",
      "Topic 5: [('fsia', 1.08), ('idaho', 1.08), ('foreign', 0.82), ('forest', 0.66), ('central', 0.56)]\n",
      "Topic 6: [('tax', 18.33), ('court', 14.52), ('action', 13.93), ('board', 12.61), ('plan', 12.38)]\n",
      "Topic 7: [('lovings', 0.57), ('walton', 0.46), ('chapel', 0.38), ('inability', 0.38), ('fdca', 0.36)]\n",
      "Topic 8: [('rico', 2.82), ('racketeer', 1.1), ('corrupt', 1.07), ('influenced', 1.05), ('districting', 0.76)]\n",
      "Topic 9: [('clinton', 0.77), ('busing', 0.74), ('stamp', 0.56), ('tolling', 0.48), ('reopen', 0.46)]\n",
      "Topic 10: [('redistricting', 2.28), ('plan', 1.5), ('voting', 1.42), ('census', 1.25), ('black', 0.88)]\n",
      "Topic 11: [('boynton', 0.62), ('sa', 0.57), ('hoffa', 0.53), ('ptab', 0.51), ('informer', 0.5)]\n",
      "Topic 12: [('school', 15.79), ('student', 7.16), ('high', 2.51), ('black', 1.94), ('racial', 1.68)]\n",
      "Topic 13: [('deck', 0.84), ('flower', 0.76), ('jama', 0.71), ('victim', 0.64), ('hazen', 0.57)]\n",
      "Topic 14: [('puerto', 2.6), ('rico', 1.92), ('tyler', 0.83), ('thompkins', 0.73), ('liquid', 0.68)]\n",
      "Topic 15: [('gambling', 1.09), ('indian', 0.84), ('mcdonough', 0.62), ('proxy', 0.47), ('nussle', 0.42)]\n",
      "Topic 16: [('wilson', 0.58), ('mdi', 0.55), ('dress', 0.52), ('design', 0.44), ('recio', 0.37)]\n",
      "Topic 17: [('age', 2.92), ('adea', 2.24), ('heroin', 1.2), ('chicago', 1.08), ('maximum', 1.06)]\n",
      "Topic 18: [('called', 0.64), ('atkins', 0.63), ('outofstate', 0.59), ('offensive', 0.58), ('community', 0.56)]\n",
      "Topic 19: [('clay', 0.67), ('greene', 0.48), ('usace', 0.41), ('suttons', 0.38), ('daughter', 0.32)]\n",
      "Topic 20: [('otcs', 0.73), ('perry', 0.71), ('beggerly', 0.55), ('rotary', 0.53), ('oregon', 0.53)]\n",
      "Topic 21: [('maine', 1.05), ('flag', 0.79), ('titlow', 0.79), ('forney', 0.71), ('probation', 0.66)]\n",
      "Topic 22: [('erisa', 1.24), ('income', 0.85), ('claimant', 0.79), ('pastdue', 0.68), ('petrella', 0.67)]\n",
      "Topic 23: [('bar', 0.76), ('murphy', 0.7), ('volvo', 0.6), ('length', 0.49), ('reeder', 0.45)]\n",
      "Topic 24: [('angeles', 1.78), ('los', 1.75), ('teacher', 0.93), ('airport', 0.8), ('complete', 0.76)]\n",
      "Topic 25: [('castro', 0.64), ('university', 0.61), ('nizchavez', 0.49), ('ballot', 0.49), ('cornerstone', 0.44)]\n",
      "Topic 26: [('visciotti', 0.72), ('drug', 0.57), ('hen', 0.51), ('rodgers', 0.5), ('zedner', 0.46)]\n",
      "Topic 27: [('illegitimate', 0.76), ('horowitz', 0.68), ('mission', 0.67), ('omega', 0.62), ('nike', 0.59)]\n",
      "Topic 28: [('moncrieffe', 0.76), ('shepard', 0.7), ('tssaa', 0.6), ('landrigan', 0.59), ('landrigans', 0.52)]\n",
      "Topic 29: [('driver', 1.27), ('deference', 1.26), ('davila', 0.81), ('brumfield', 0.64), ('cwa', 0.62)]\n",
      "Topic 30: [('advertising', 0.79), ('inquiry', 0.48), ('csx', 0.45), ('arbour', 0.45), ('investor', 0.44)]\n",
      "Topic 31: [('intermediary', 0.72), ('burbine', 0.71), ('archer', 0.57), ('haymond', 0.51), ('warner', 0.51)]\n",
      "Topic 32: [('setser', 0.69), ('tucker', 0.6), ('ressam', 0.54), ('explosive', 0.49), ('reaching', 0.27)]\n",
      "Topic 33: [('connelly', 0.74), ('pertinent', 0.63), ('davis', 0.54), ('haynes', 0.49), ('condominium', 0.44)]\n",
      "Topic 34: [('sander', 0.59), ('faulted', 0.16), ('affected', 0.11), ('told', 0.1), ('consider', 0.01)]\n",
      "Topic 35: [('punitive', 1.17), ('guam', 0.82), ('coverage', 0.81), ('arbitrary', 0.79), ('dai', 0.75)]\n",
      "Topic 36: [('howard', 0.63), ('raisin', 0.62), ('checkpoint', 0.61), ('negusie', 0.6), ('vice', 0.59)]\n",
      "Topic 37: [('store', 0.85), ('town', 0.75), ('houston', 0.68), ('carle', 0.62), ('proposition', 0.62)]\n",
      "Topic 38: [('supervisor', 1.01), ('palmer', 0.72), ('laidlaw', 0.63), ('training', 0.61), ('nelson', 0.56)]\n",
      "Topic 39: [('democrat', 0.9), ('bullock', 0.73), ('corbin', 0.6), ('connell', 0.59), ('coolidge', 0.58)]\n",
      "Topic 40: [('missouri', 0.81), ('belmontes', 0.74), ('lucas', 0.49), ('waterhouse', 0.48), ('hopkins', 0.48)]\n",
      "Topic 41: [('marathon', 0.86), ('center', 0.77), ('bush', 0.73), ('glenn', 0.67), ('boyle', 0.6)]\n",
      "Topic 42: [('liv', 0.53), ('video', 0.42), ('severance', 0.39), ('store', 0.38), ('dupont', 0.38)]\n",
      "Topic 43: [('crooker', 0.74), ('fikes', 0.7), ('confession', 0.64), ('allen', 0.54), ('ayala', 0.54)]\n",
      "Topic 44: [('trust', 1.18), ('ad', 0.87), ('ideal', 0.52), ('brady', 0.45), ('trustee', 0.39)]\n",
      "Topic 45: [('nixon', 1.51), ('lot', 0.99), ('uranium', 0.67), ('evans', 0.58), ('924c1aiii', 0.55)]\n",
      "Topic 46: [('acca', 2.68), ('violent', 1.96), ('career', 1.76), ('armed', 1.66), ('felon', 1.25)]\n",
      "Topic 47: [('oracle', 0.67), ('afroyim', 0.65), ('enterprise', 0.52), ('woman', 0.43), ('rimini', 0.43)]\n",
      "Topic 48: [('defraud', 0.77), ('kaleys', 0.76), ('rosenbloom', 0.63), ('edward', 0.63), ('implement', 0.6)]\n",
      "Topic 49: [('alabama', 4.91), ('naacp', 1.93), ('located', 1.51), ('irs', 1.44), ('accident', 1.34)]\n",
      "Topic 50: [('adam', 0.8), ('henry', 0.73), ('small', 0.67), ('punishable', 0.59), ('birth', 0.54)]\n",
      "Topic 51: [('ta', 0.49), ('102', 0.46), ('cedar', 0.45), ('hamm', 0.45), ('ufw', 0.44)]\n",
      "Topic 52: [('cost', 1.24), ('mexican', 1.02), ('royalty', 0.82), ('kingsley', 0.72), ('isda', 0.68)]\n",
      "Topic 53: [('aedpa', 1.86), ('antiterrorism', 1.27), ('robbins', 0.73), ('simon', 0.53), ('wyner', 0.53)]\n",
      "Topic 54: [('lancaster', 0.73), ('brother', 0.72), ('bfp', 0.7), ('rogers', 0.61), ('hillman', 0.6)]\n",
      "Topic 55: [('hillery', 0.69), ('shatzer', 0.53), ('waffle', 0.45), ('miranda', 0.44), ('invoked', 0.44)]\n",
      "Topic 56: [('doe', 0.68), ('fpc', 0.58), ('dune', 0.53), ('del', 0.53), ('monte', 0.5)]\n",
      "Topic 57: [('establishment', 2.2), ('justified', 1.05), ('religion', 0.97), ('massachusetts', 0.93), ('display', 0.78)]\n",
      "Topic 58: [('le', 0.8), ('tennessee', 0.76), ('hill', 0.62), ('musacchio', 0.57), ('sentilles', 0.57)]\n",
      "Topic 59: [('warren', 0.54), ('leu', 0.53), ('connaughton', 0.5), ('ancsa', 0.45), ('antidumping', 0.42)]\n",
      "Topic 60: [('antitrust', 2.11), ('sherman', 1.29), ('retail', 1.13), ('price', 1.0), ('fiduciary', 0.99)]\n",
      "Topic 61: [('airline', 0.81), ('tribe', 0.6), ('warn', 0.5), ('craft', 0.45), ('predatory', 0.45)]\n",
      "Topic 62: [('impact', 0.95), ('victim', 0.83), ('doe', 0.62), ('rickard', 0.58), ('family', 0.54)]\n",
      "Topic 63: [('mcfl', 0.56), ('lorenzo', 0.47), ('flyer', 0.41), ('deduction', 0.41), ('rettele', 0.36)]\n",
      "Topic 64: [('sibron', 0.59), ('running', 0.52), ('menominee', 0.5), ('tribe', 0.5), ('charter', 0.44)]\n",
      "Topic 65: [('title', 2.67), ('vii', 2.56), ('1964', 1.2), ('rhine', 0.78), ('eeoc', 0.72)]\n",
      "Topic 66: [('retaliatory', 0.7), ('burma', 0.65), ('inmate', 0.5), ('page', 0.5), ('telecommunication', 0.39)]\n",
      "Topic 67: [('splash', 0.63), ('girl', 0.49), ('abdulkabir', 0.46), ('jackson', 0.43), ('menon', 0.42)]\n",
      "Topic 68: [('man', 1.33), ('real', 0.82), ('black', 0.8), ('race', 0.66), ('maslenjak', 0.65)]\n",
      "Topic 69: [('pension', 1.0), ('gain', 0.6), ('carlisle', 0.6), ('hfa', 0.57), ('ssdi', 0.53)]\n",
      "Topic 70: [('barker', 0.76), ('harris', 0.56), ('estate', 0.51), ('wearry', 0.46), ('wearrys', 0.46)]\n",
      "Topic 71: [('blood', 0.81), ('ftb', 0.6), ('rabkin', 0.59), ('oath', 0.48), ('insider', 0.45)]\n",
      "Topic 72: [('court', 21.69), ('death', 15.27), ('trial', 15.25), ('sentence', 15.17), ('jury', 14.26)]\n",
      "Topic 73: [('pollard', 1.05), ('young', 0.73), ('jackson', 0.72), ('cftb', 0.6), ('daca', 0.57)]\n",
      "Topic 74: [('harris', 0.71), ('hargis', 0.57), ('ttab', 0.47), ('nelson', 0.44), ('21st', 0.38)]\n",
      "Topic 75: [('oregon', 0.77), ('redding', 0.58), ('waste', 0.55), ('ibm', 0.55), ('va', 0.55)]\n",
      "Topic 76: [('watson', 0.69), ('atchley', 0.62), ('returning', 0.51), ('ross', 0.51), ('dravo', 0.45)]\n",
      "Topic 77: [('barn', 0.66), ('refugee', 0.51), ('stoddard', 0.5), ('dunns', 0.44), ('waste', 0.42)]\n",
      "Topic 78: [('restitution', 0.97), ('washington', 0.49), ('young', 0.49), ('tip', 0.47), ('witters', 0.46)]\n",
      "Topic 79: [('batson', 1.81), ('simmons', 1.49), ('selection', 1.41), ('mitigating', 1.33), ('hayes', 1.28)]\n",
      "Topic 80: [('retroactively', 0.78), ('innis', 0.74), ('berenyi', 0.66), ('cohen', 0.63), ('ct', 0.52)]\n",
      "Topic 81: [('halbert', 0.71), ('nigh', 0.6), ('green', 0.54), ('franklin', 0.54), ('ayestas', 0.54)]\n",
      "Topic 82: [('assessment', 0.98), ('marketing', 0.78), ('agricultural', 0.64), ('banks', 0.46), ('nonmember', 0.46)]\n",
      "Topic 83: [('bond', 0.58), ('bradley', 0.58), ('hb', 0.43), ('variance', 0.43), ('tribe', 0.42)]\n",
      "Topic 84: [('cole', 0.82), ('mineral', 0.67), ('chattanooga', 0.53), ('radioactive', 0.51), ('waste', 0.5)]\n",
      "Topic 85: [('alaska', 2.27), ('remedy', 1.35), ('speech', 1.27), ('society', 1.23), ('crack', 1.2)]\n",
      "Topic 86: [('creation', 0.9), ('barge', 0.74), ('union', 0.72), ('insufficient', 0.7), ('gm', 0.68)]\n",
      "Topic 87: [('saving', 0.74), ('russell', 0.64), ('mortgage', 0.63), ('aaron', 0.53), ('johnson', 0.52)]\n",
      "Topic 88: [('hudson', 0.53), ('herald', 0.5), ('village', 0.5), ('vfoia', 0.49), ('mcburney', 0.49)]\n",
      "Topic 89: [('hospital', 1.42), ('reimbursement', 1.3), ('refund', 1.02), ('iowa', 0.93), ('football', 0.89)]\n",
      "Topic 90: [('ohralik', 0.62), ('sugar', 0.56), ('gorman', 0.52), ('andor', 0.51), ('cuba', 0.47)]\n",
      "Topic 91: [('lange', 0.89), ('herring', 0.66), ('blueford', 0.56), ('fmcsa', 0.55), ('deposition', 0.54)]\n",
      "Topic 92: [('henderson', 0.8), ('stored', 0.64), ('tiebreaker', 0.59), ('microsoft', 0.43), ('branch', 0.34)]\n",
      "Topic 93: [('muniz', 0.73), ('carjacking', 0.6), ('gertz', 0.54), ('farm', 0.41), ('contracted', 0.37)]\n",
      "Topic 94: [('wesberry', 0.56), ('magazine', 0.49), ('butterfield', 0.42), ('harlow', 0.42), ('austin', 0.31)]\n",
      "Topic 95: [('reliance', 0.63), ('hardt', 0.52), ('blue', 0.44), ('bullard', 0.44), ('fox', 0.42)]\n",
      "Topic 96: [('huff', 0.72), ('lucky', 0.68), ('mccutchen', 0.65), ('ohler', 0.62), ('sundiamond', 0.6)]\n",
      "Topic 97: [('seized', 1.33), ('lyon', 1.11), ('seizure', 0.8), ('romeo', 0.78), ('residence', 0.73)]\n",
      "Topic 98: [('bank', 1.02), ('university', 0.97), ('marquez', 0.69), ('admission', 0.65), ('plumer', 0.65)]\n",
      "Topic 99: [('court', 26.73), ('claim', 15.88), ('state', 15.78), ('suit', 15.21), ('district', 11.35)]\n",
      "Topic 100: [('court', 32.61), ('state', 21.63), ('officer', 19.74), ('police', 17.54), ('district', 16.03)]\n",
      "Topic 101: [('doggett', 0.68), ('road', 0.62), ('traveling', 0.51), ('dea', 0.48), ('fare', 0.42)]\n",
      "Topic 102: [('post', 1.48), ('facto', 1.14), ('ex', 1.09), ('jimenez', 0.83), ('working', 0.54)]\n",
      "Topic 103: [('moore', 0.73), ('stolen', 0.71), ('motorcycle', 0.64), ('morrison', 0.57), ('stewart', 0.55)]\n",
      "Topic 104: [('carolina', 3.4), ('north', 3.08), ('university', 0.78), ('france', 0.7), ('tire', 0.55)]\n",
      "Topic 105: [('hardwick', 0.71), ('king', 0.63), ('barefoot', 0.54), ('ftca', 0.46), ('sodomy', 0.33)]\n",
      "Topic 106: [('decree', 1.49), ('vehicle', 0.95), ('taggart', 0.55), ('thornton', 0.54), ('religious', 0.46)]\n",
      "Topic 107: [('entergy', 0.59), ('graham', 0.56), ('iolta', 0.54), ('oubre', 0.49), ('solid', 0.46)]\n",
      "Topic 108: [('socket', 0.67), ('spouse', 0.64), ('betts', 0.6), ('mickens', 0.54), ('bartholomew', 0.46)]\n",
      "Topic 109: [('simpson', 0.63), ('counter', 0.62), ('samantar', 0.5), ('store', 0.5), ('material', 0.45)]\n",
      "Topic 110: [('african', 1.06), ('anderson', 0.67), ('orr', 0.66), ('attachment', 0.53), ('pole', 0.51)]\n",
      "Topic 111: [('threat', 0.95), ('shelton', 0.62), ('westside', 0.54), ('miller', 0.53), ('orden', 0.51)]\n",
      "Topic 112: [('warning', 0.91), ('bryant', 0.77), ('fisher', 0.69), ('miranda', 0.69), ('waller', 0.61)]\n",
      "Topic 113: [('154', 0.55), ('banister', 0.46), ('kawaauhau', 0.45), ('retailer', 0.44), ('coa', 0.42)]\n",
      "Topic 114: [('spink', 0.71), ('akamai', 0.52), ('lockheed', 0.48), ('xerox', 0.46), ('dickerson', 0.44)]\n",
      "Topic 115: [('litigation', 2.05), ('official', 2.0), ('separate', 1.78), ('eleventh', 1.7), ('reform', 1.64)]\n",
      "Topic 116: [('church', 1.36), ('senate', 0.61), ('authority', 0.52), ('walz', 0.51), ('hospital', 0.49)]\n",
      "Topic 117: [('richards', 0.66), ('dc', 0.63), ('clair', 0.62), ('enmund', 0.6), ('slusa', 0.6)]\n",
      "Topic 118: [('gray', 1.59), ('library', 0.49), ('bell', 0.48), ('sims', 0.47), ('mercexchange', 0.42)]\n",
      "Topic 119: [('agee', 0.73), ('welsh', 0.6), ('924c1', 0.56), ('delaware', 0.52), ('cfi', 0.49)]\n",
      "Topic 120: [('bspa', 0.6), ('mims', 0.51), ('tcpa', 0.47), ('beach', 0.44), ('university', 0.41)]\n",
      "Topic 121: [('tribal', 1.39), ('slack', 0.87), ('alex', 0.81), ('received', 0.77), ('unsuccessfully', 0.76)]\n",
      "Topic 122: [('111', 0.72), ('scholarship', 0.62), ('dawson', 0.58), ('bogan', 0.49), ('granfinanciera', 0.49)]\n",
      "Topic 123: [('candidate', 2.82), ('ballot', 1.69), ('campaign', 1.01), ('contribution', 0.83), ('unknown', 0.83)]\n",
      "Topic 124: [('certificate', 0.74), ('greene', 0.73), ('ash', 0.64), ('tyson', 0.46), ('oneida', 0.43)]\n",
      "Topic 125: [('capacity', 1.13), ('official', 1.07), ('land', 0.75), ('bies', 0.62), ('suders', 0.62)]\n",
      "Topic 126: [('care', 1.66), ('medicaid', 1.64), ('privacy', 1.36), ('health', 1.36), ('secured', 0.85)]\n",
      "Topic 127: [('coal', 0.69), ('wiggins', 0.66), ('alafabco', 0.58), ('logan', 0.52), ('crew', 0.52)]\n",
      "Topic 128: [('taking', 0.99), ('animal', 0.51), ('northwest', 0.48), ('till', 0.44), ('santeria', 0.42)]\n",
      "Topic 129: [('water', 2.46), ('point', 1.3), ('pollutant', 0.68), ('knetsch', 0.58), ('lozman', 0.55)]\n",
      "Topic 130: [('pension', 0.6), ('2626', 0.52), ('beck', 0.5), ('prupis', 0.5), ('esa', 0.48)]\n",
      "Topic 131: [('parking', 0.8), ('restaurant', 0.65), ('kyles', 0.65), ('loughrin', 0.57), ('station', 0.47)]\n",
      "Topic 132: [('davis', 0.83), ('commitment', 0.72), ('qualified', 0.52), ('tank', 0.41), ('suspicion', 0.38)]\n",
      "Topic 133: [('violence', 0.82), ('ash', 0.69), ('dimaya', 0.68), ('decedent', 0.61), ('zicherman', 0.57)]\n",
      "Topic 134: [('salina', 0.86), ('fowler', 0.63), ('horner', 0.53), ('lethal', 0.45), ('reapportionment', 0.43)]\n",
      "Topic 135: [('bargaining', 2.13), ('collective', 1.8), ('free', 1.65), ('failing', 1.6), ('faa', 1.58)]\n",
      "Topic 136: [('welfare', 0.83), ('hampshire', 0.82), ('noncitizen', 0.68), ('dna', 0.62), ('cisco', 0.6)]\n",
      "Topic 137: [('gideon', 0.66), ('adam', 0.58), ('foundation', 0.58), ('iolta', 0.55), ('citibank', 0.54)]\n",
      "Topic 138: [('apportionment', 1.46), ('ncaa', 1.04), ('grazing', 0.77), ('crawford', 0.62), ('mont', 0.62)]\n",
      "Topic 139: [('immigration', 5.1), ('ina', 2.07), ('nationality', 1.68), ('bia', 1.53), ('asylum', 1.45)]\n",
      "Topic 140: [('reserve', 1.27), ('unavailable', 0.86), ('gonzales', 0.75), ('milk', 0.74), ('mallory', 0.71)]\n",
      "Topic 141: [('icc', 2.62), ('interstate', 1.61), ('commerce', 1.51), ('pipeline', 0.63), ('pereida', 0.61)]\n",
      "Topic 142: [('union', 4.02), ('nlrb', 1.39), ('affidavit', 1.24), ('labor', 1.13), ('relation', 1.1)]\n",
      "Topic 143: [('chavis', 0.79), ('alleyne', 0.49), ('318', 0.44), ('lopez', 0.43), ('jackson', 0.43)]\n",
      "Topic 144: [('trailer', 0.59), ('policy', 0.48), ('irs', 0.43), ('love', 0.39), ('transaction', 0.36)]\n",
      "Topic 145: [('matthew', 0.73), ('kirtsaeng', 0.66), ('matlock', 0.65), ('herdman', 0.57), ('lambrix', 0.52)]\n",
      "Topic 146: [('cicenia', 0.74), ('arbitrability', 0.65), ('distributor', 0.63), ('camara', 0.61), ('device', 0.61)]\n",
      "Topic 147: [('colorado', 1.06), ('alliance', 0.86), ('montgomery', 0.71), ('davis', 0.64), ('st', 0.64)]\n",
      "Topic 148: [('rosemond', 0.72), ('griffin', 0.67), ('transcript', 0.62), ('wilkinson', 0.57), ('antonio', 0.51)]\n",
      "Topic 149: [('sport', 0.64), ('cantu', 0.46), ('slate', 0.45), ('bond', 0.44), ('league', 0.43)]\n",
      "Topic 150: [('mitt', 0.65), ('fhfa', 0.53), ('jesinoskis', 0.47), ('suisse', 0.46), ('strickler', 0.42)]\n",
      "Topic 151: [('section', 8.56), ('congress', 8.23), ('general', 6.82), ('election', 6.0), ('power', 5.67)]\n",
      "Topic 152: [('dependent', 1.19), ('husband', 0.68), ('hertz', 0.66), ('humphries', 0.63), ('withholding', 0.58)]\n",
      "Topic 153: [('pepper', 0.66), ('daniel', 0.55), ('brada', 0.55), ('harris', 0.51), ('transamerican', 0.47)]\n",
      "Topic 154: [('lawyer', 1.05), ('patten', 0.64), ('martinezvillareal', 0.54), ('van', 0.51), ('link', 0.44)]\n",
      "Topic 155: [('guideline', 1.38), ('field', 1.24), ('iii', 0.91), ('gram', 0.81), ('powell', 0.75)]\n",
      "Topic 156: [('perkins', 1.14), ('drayton', 0.52), ('compucredit', 0.45), ('longshore', 0.45), ('lhwca', 0.38)]\n",
      "Topic 157: [('georgia', 0.79), ('mead', 0.56), ('mcpherson', 0.54), ('civilian', 0.54), ('29c', 0.48)]\n",
      "Topic 158: [('hamilton', 0.53), ('rfra', 0.53), ('posing', 0.52), ('satp', 0.48), ('darter', 0.39)]\n",
      "Topic 159: [('foia', 0.95), ('icon', 0.64), ('balisok', 0.62), ('octane', 0.48), ('exempts', 0.46)]\n",
      "Topic 160: [('procedurally', 0.77), ('bond', 0.75), ('vinson', 0.52), ('carpenter', 0.44), ('worth', 0.41)]\n",
      "Topic 161: [('elector', 1.05), ('rodriguezmoreno', 0.68), ('arkansas', 0.64), ('porter', 0.59), ('selective', 0.59)]\n",
      "Topic 162: [('gas', 1.37), ('oil', 1.23), ('montana', 0.85), ('ring', 0.8), ('egelhoff', 0.72)]\n",
      "Topic 163: [('carrier', 0.57), ('heartland', 0.49), ('ethanol', 0.48), ('tvpa', 0.47), ('insider', 0.46)]\n",
      "Topic 164: [('patent', 8.88), ('usc', 6.15), ('limitation', 5.43), ('order', 5.28), ('awarded', 5.25)]\n",
      "Topic 165: [('available', 1.45), ('parcel', 0.73), ('cwa', 0.66), ('device', 0.55), ('picketing', 0.54)]\n",
      "Topic 166: [('land', 4.32), ('indian', 1.64), ('band', 1.29), ('interior', 1.22), ('area', 0.93)]\n",
      "Topic 167: [('arbitration', 7.07), ('agreement', 3.25), ('dispute', 2.48), ('sovereign', 2.28), ('corporation', 2.25)]\n",
      "Topic 168: [('bg', 0.58), ('savchuk', 0.56), ('rush', 0.53), ('argentina', 0.47), ('butz', 0.46)]\n",
      "Topic 169: [('domestic', 1.7), ('violence', 1.28), ('misdemeanor', 1.06), ('expense', 0.95), ('wire', 0.91)]\n",
      "Topic 170: [('pornography', 1.03), ('discriminatory', 0.94), ('racially', 0.79), ('material', 0.77), ('private', 0.71)]\n",
      "Topic 171: [('section', 3.72), ('tribe', 3.61), ('alien', 3.18), ('discharge', 2.8), ('favor', 2.67)]\n",
      "Topic 172: [('spano', 0.74), ('1975', 0.65), ('andrade', 0.57), ('prospective', 0.49), ('witherspoon', 0.45)]\n",
      "Topic 173: [('fernandezvargas', 0.59), ('arco', 0.52), ('oconnor', 0.52), ('usa', 0.48), ('ali', 0.36)]\n",
      "Topic 174: [('distress', 0.77), ('haynes', 0.71), ('peel', 0.6), ('tsakopoulos', 0.59), ('williams', 0.56)]\n",
      "Topic 175: [('brown', 1.39), ('boycott', 0.75), ('924c1', 0.69), ('foster', 0.64), ('deal', 0.62)]\n",
      "Topic 176: [('yang', 0.7), ('lindh', 0.54), ('sprint', 0.53), ('iub', 0.42), ('pope', 0.38)]\n",
      "Topic 177: [('alj', 0.95), ('basic', 0.88), ('faretta', 0.74), ('michael', 0.71), ('tenant', 0.68)]\n",
      "Topic 178: [('zenith', 0.7), ('abramski', 0.69), ('ifc', 0.68), ('adelaide', 0.59), ('patane', 0.59)]\n",
      "Topic 179: [('psychiatrist', 0.75), ('ake', 0.71), ('parole', 0.67), ('mimms', 0.66), ('laundering', 0.6)]\n",
      "Topic 180: [('fitzgerald', 0.67), ('capacity', 0.64), ('recording', 0.63), ('donation', 0.62), ('landmark', 0.6)]\n",
      "Topic 181: [('partnership', 1.65), ('management', 1.37), ('revenue', 1.26), ('justice', 1.17), ('assessed', 0.96)]\n",
      "Topic 182: [('reef', 0.74), ('vl', 0.59), ('oxford', 0.55), ('confinement', 0.55), ('el', 0.48)]\n",
      "Topic 183: [('cruel', 1.51), ('unusual', 1.47), ('woodson', 0.99), ('gregg', 0.98), ('gamble', 0.82)]\n",
      "Topic 184: [('interrogation', 0.63), ('stump', 0.55), ('rivet', 0.48), ('sparkman', 0.44), ('callahan', 0.4)]\n",
      "Topic 185: [('fannie', 0.78), ('vickie', 0.67), ('nichols', 0.62), ('apjs', 0.59), ('campbell', 0.56)]\n",
      "Topic 186: [('fdcpa', 0.86), ('authority', 0.86), ('health', 0.84), ('private', 0.73), ('1970', 0.67)]\n",
      "Topic 187: [('james', 0.58), ('lawson', 0.56), ('lexmark', 0.51), ('martin', 0.5), ('grady', 0.45)]\n",
      "Topic 188: [('stanton', 0.78), ('escobedo', 0.7), ('riggins', 0.68), ('trinity', 0.61), ('vendor', 0.58)]\n",
      "Topic 189: [('townsend', 0.75), ('peguero', 0.66), ('saratoga', 0.62), ('randolph', 0.5), ('hamdis', 0.45)]\n",
      "Topic 190: [('herrera', 0.64), ('matrixx', 0.43), ('herreras', 0.41), ('deputy', 0.41), ('geico', 0.4)]\n",
      "Topic 191: [('mansell', 0.88), ('reduction', 0.8), ('mclane', 0.72), ('regulate', 0.69), ('ashcroft', 0.67)]\n",
      "Topic 192: [('edmondson', 0.54), ('propulsion', 0.48), ('citgo', 0.46), ('frescati', 0.46), ('transamerica', 0.4)]\n",
      "Topic 193: [('access', 1.26), ('improper', 1.06), ('staff', 0.72), ('primus', 0.71), ('channel', 0.65)]\n",
      "Topic 194: [('debtor', 1.7), ('13', 1.27), ('fine', 0.84), ('bankruptcy', 0.7), ('showing', 0.64)]\n",
      "Topic 195: [('ford', 1.75), ('brady', 1.21), ('fox', 0.76), ('parole', 0.75), ('oneyear', 0.72)]\n",
      "Topic 196: [('arnold', 0.54), ('benjamin', 0.52), ('distributor', 0.49), ('game', 0.49), ('annotation', 0.48)]\n",
      "Topic 197: [('rompillas', 0.7), ('gonzalez', 0.6), ('sheehan', 0.59), ('schad', 0.56), ('kholi', 0.53)]\n",
      "Topic 198: [('currently', 1.9), ('specie', 1.38), ('endangered', 1.21), ('standing', 1.09), ('wildlife', 0.75)]\n",
      "Topic 199: [('advice', 0.77), ('madison', 0.73), ('travel', 0.71), ('passport', 0.6), ('coker', 0.54)]\n",
      "Topic 200: [('cia', 0.58), ('adam', 0.58), ('obb', 0.53), ('tribe', 0.51), ('novo', 0.47)]\n"
     ]
    }
   ],
   "source": [
    "# LDA 학습 결과 보기\n",
    "terms = vectorizeTF.get_feature_names_out()\n",
    "\n",
    "def get_topics(components, feature_names, n=5): # n: n개 출력\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "\n",
    "get_topics(lda.components_,terms)\n",
    "\n",
    "# 토픽과 토픽에 대한 기여도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG부스트 모델 적용하기\n",
    "\n",
    "model = XGBClassifier()\n",
    "x = pd.DataFrame(data=lda_data)\n",
    "model.fit(x, y_train)\n",
    "x_test = pd.DataFrame(data=lda.transform(X_test))\n",
    "y_pred = model.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.08%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7206020696142993"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트csv 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facts</th>\n",
       "      <th>facts_clean</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The 1984 Bail Reform Act allowed the federal c...</td>\n",
       "      <td>1984 bail reform act allowed federal court det...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lexecon Inc. was a defendant in a class action...</td>\n",
       "      <td>lexecon inc defendant class action lawsuit 28 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In 2002 and 2003, Fox Television Stations broa...</td>\n",
       "      <td>2002 2003 fox television station broadcast bil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>During his trial for armed robbery of a federa...</td>\n",
       "      <td>trial armed robbery federally insured saving l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In 1993, a magistrate judge issued a warrant a...</td>\n",
       "      <td>1993 magistrate judge issued warrant authorizi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>According to Executive Order No. 12807 signed ...</td>\n",
       "      <td>according executive order 12807 signed preside...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>Section 109(a) of the Clean Air Act (CAA) requ...</td>\n",
       "      <td>section 109a clean air act caa requires enviro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>Linda Matteo and John Madigan created a plan f...</td>\n",
       "      <td>linda matteo john madigan created plan utilizi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>In 1972, the North Carolina Board of Agricultu...</td>\n",
       "      <td>1972 north carolina board agriculture adopted ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>On August 23, 1961, Dr. Paul Berheldt was stab...</td>\n",
       "      <td>august 23 1961 dr paul berheldt stabbed death ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  facts  \\\n",
       "0     The 1984 Bail Reform Act allowed the federal c...   \n",
       "1     Lexecon Inc. was a defendant in a class action...   \n",
       "2     In 2002 and 2003, Fox Television Stations broa...   \n",
       "3     During his trial for armed robbery of a federa...   \n",
       "4     In 1993, a magistrate judge issued a warrant a...   \n",
       "...                                                 ...   \n",
       "1235  According to Executive Order No. 12807 signed ...   \n",
       "1236  Section 109(a) of the Clean Air Act (CAA) requ...   \n",
       "1237  Linda Matteo and John Madigan created a plan f...   \n",
       "1238  In 1972, the North Carolina Board of Agricultu...   \n",
       "1239  On August 23, 1961, Dr. Paul Berheldt was stab...   \n",
       "\n",
       "                                            facts_clean  first_party_winner  \n",
       "0     1984 bail reform act allowed federal court det...                   0  \n",
       "1     lexecon inc defendant class action lawsuit 28 ...                   0  \n",
       "2     2002 2003 fox television station broadcast bil...                   0  \n",
       "3     trial armed robbery federally insured saving l...                   0  \n",
       "4     1993 magistrate judge issued warrant authorizi...                   0  \n",
       "...                                                 ...                 ...  \n",
       "1235  according executive order 12807 signed preside...                   0  \n",
       "1236  section 109a clean air act caa requires enviro...                   0  \n",
       "1237  linda matteo john madigan created plan utilizi...                   0  \n",
       "1238  1972 north carolina board agriculture adopted ...                   0  \n",
       "1239  august 23 1961 dr paul berheldt stabbed death ...                   0  \n",
       "\n",
       "[1240 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest = pd.DataFrame(test['facts'])\n",
    "dfTest['facts'] = dfTest['facts'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "dfTest[\"facts_clean\"] = dfTest[\"facts\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=lst_stopwords))\n",
    "dfTest['first_party_winner'] = np.zeros(len(dfTest)).astype(int)\n",
    "dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>011119</th>\n",
       "      <th>0125</th>\n",
       "      <th>02</th>\n",
       "      <th>036539</th>\n",
       "      <th>04</th>\n",
       "      <th>041352</th>\n",
       "      <th>041581</th>\n",
       "      <th>0479</th>\n",
       "      <th>05</th>\n",
       "      <th>0511287</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoned</th>\n",
       "      <th>zoneofinterests</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zubik</th>\n",
       "      <th>zuni</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zurko</th>\n",
       "      <th>zurkos</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 17810 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      011119  0125   02  036539   04  041352  041581  0479   05  0511287  ...  \\\n",
       "0        0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "1        0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "2        0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "3        0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "4        0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "...      ...   ...  ...     ...  ...     ...     ...   ...  ...      ...  ...   \n",
       "1235     0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "1236     0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "1237     0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "1238     0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "1239     0.0   0.0  0.0     0.0  0.0     0.0     0.0   0.0  0.0      0.0  ...   \n",
       "\n",
       "      zone  zoned  zoneofinterests  zoning  zubik  zuni  zurich  zurko  \\\n",
       "0      0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "1      0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "2      0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "3      0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "4      0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "...    ...    ...              ...     ...    ...   ...     ...    ...   \n",
       "1235   0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "1236   0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "1237   0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "1238   0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "1239   0.0    0.0              0.0     0.0    0.0   0.0     0.0    0.0   \n",
       "\n",
       "      zurkos  first_party_winner  \n",
       "0        0.0                   0  \n",
       "1        0.0                   0  \n",
       "2        0.0                   0  \n",
       "3        0.0                   0  \n",
       "4        0.0                   0  \n",
       "...      ...                 ...  \n",
       "1235     0.0                   0  \n",
       "1236     0.0                   0  \n",
       "1237     0.0                   0  \n",
       "1238     0.0                   0  \n",
       "1239     0.0                   0  \n",
       "\n",
       "[1240 rows x 17810 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix_test = vectorizeTF.transform(dfTest['facts_clean'])\n",
    "count_array_test = count_matrix_test.toarray()\n",
    "data_final_test = pd.DataFrame(data=count_array_test,columns = vectorizeTF.get_feature_names_out())\n",
    "data_final_test = pd.concat([data_final_test,dfTest[\"first_party_winner\"]],axis=1,join='inner')\n",
    "data_final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_final_test.drop(columns=['first_party_winner'])\n",
    "y_test = data_final_test['first_party_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lda_test = pd.DataFrame(data=lda.fit_transform(X_test))\n",
    "y_pred_test = model.predict(x_lda_test)\n",
    "predictionsTest = [round(value) for value in y_pred_test]\n",
    "predcsv = pd.DataFrame(predictionsTest,columns=['first_party_winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('C:/data/project/sample_submission.csv')\n",
    "submit['first_party_winner'] = predcsv\n",
    "submit.to_csv('./sample_submission.csv', index=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_party_winner\n",
       "0                     918\n",
       "1                     322\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predcsv.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
