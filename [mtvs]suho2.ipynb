{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "## for data\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk## for language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>Phil A. St. Amant</td>\n",
       "      <td>Herman A. Thompson</td>\n",
       "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Stephen Duncan</td>\n",
       "      <td>Lawrence Owens</td>\n",
       "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>Billy Joe Magwood</td>\n",
       "      <td>Tony Patterson, Warden, et al.</td>\n",
       "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Linkletter</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Victor Linkletter was convicted in state court...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>William Earl Fikes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID         first_party                    second_party  \\\n",
       "0  TRAIN_0000   Phil A. St. Amant              Herman A. Thompson   \n",
       "1  TRAIN_0001      Stephen Duncan                  Lawrence Owens   \n",
       "2  TRAIN_0002   Billy Joe Magwood  Tony Patterson, Warden, et al.   \n",
       "3  TRAIN_0003          Linkletter                          Walker   \n",
       "4  TRAIN_0004  William Earl Fikes                         Alabama   \n",
       "\n",
       "                                               facts  first_party_winner  \n",
       "0  On June 27, 1962, Phil St. Amant, a candidate ...                   1  \n",
       "1  Ramon Nelson was riding his bike when he suffe...                   0  \n",
       "2  An Alabama state court convicted Billy Joe Mag...                   1  \n",
       "3  Victor Linkletter was convicted in state court...                   0  \n",
       "4  On April 24, 1953 in Selma, Alabama, an intrud...                   1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('c:/data/project/train.csv')\n",
    "test = pd.read_csv('c:/data/project/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train[['facts', 'first_party_winner']]\n",
    "df_target = df[['first_party_winner']]\n",
    "df_nlp = df[['facts']]\n",
    "df_nlp1 = pd.DataFrame(df_nlp, columns=['facts'])\n",
    "df_nlp1['facts'] = df_nlp1['facts'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "\n",
    "dfTest = pd.DataFrame(test['facts'])\n",
    "dfTest['facts'] = dfTest['facts'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On',\n",
       " 'June',\n",
       " '27',\n",
       " ',',\n",
       " '1962',\n",
       " ',',\n",
       " 'Phil',\n",
       " 'St.',\n",
       " 'Amant',\n",
       " ',',\n",
       " 'a',\n",
       " 'candidate',\n",
       " 'for',\n",
       " 'public',\n",
       " 'office',\n",
       " ',',\n",
       " 'made',\n",
       " 'a',\n",
       " 'television',\n",
       " 'speech',\n",
       " 'in',\n",
       " 'Baton',\n",
       " 'Rouge',\n",
       " ',',\n",
       " 'Louisiana',\n",
       " '.',\n",
       " 'During',\n",
       " 'this',\n",
       " 'speech',\n",
       " ',',\n",
       " 'St.',\n",
       " 'Amant',\n",
       " 'accused',\n",
       " 'his',\n",
       " 'political',\n",
       " 'opponent',\n",
       " 'of',\n",
       " 'being',\n",
       " 'a',\n",
       " 'Communist',\n",
       " 'and',\n",
       " 'of',\n",
       " 'being',\n",
       " 'involved',\n",
       " 'in',\n",
       " 'criminal',\n",
       " 'activities',\n",
       " 'with',\n",
       " 'the',\n",
       " 'head',\n",
       " 'of',\n",
       " 'the',\n",
       " 'local',\n",
       " 'Teamsters',\n",
       " 'Union',\n",
       " '.',\n",
       " 'Finally',\n",
       " ',',\n",
       " 'St.',\n",
       " 'Amant',\n",
       " 'implicated',\n",
       " 'Herman',\n",
       " 'Thompson',\n",
       " ',',\n",
       " 'an',\n",
       " 'East',\n",
       " 'Baton',\n",
       " 'Rouge',\n",
       " 'deputy',\n",
       " 'sheriff',\n",
       " ',',\n",
       " 'in',\n",
       " 'a',\n",
       " 'scheme',\n",
       " 'to',\n",
       " 'move',\n",
       " 'money',\n",
       " 'between',\n",
       " 'the',\n",
       " 'Teamsters',\n",
       " 'Union',\n",
       " 'and',\n",
       " 'St.',\n",
       " 'Amant',\n",
       " '’',\n",
       " 's',\n",
       " 'political',\n",
       " 'opponent',\n",
       " '.',\n",
       " 'Thompson',\n",
       " 'successfully',\n",
       " 'sued',\n",
       " 'St.',\n",
       " 'Amant',\n",
       " 'for',\n",
       " 'defamation',\n",
       " '.',\n",
       " 'Louisiana',\n",
       " '’',\n",
       " 's',\n",
       " 'First',\n",
       " 'Circuit',\n",
       " 'Court',\n",
       " 'of',\n",
       " 'Appeals',\n",
       " 'reversed',\n",
       " ',',\n",
       " 'holding',\n",
       " 'that',\n",
       " 'Thompson',\n",
       " 'did',\n",
       " 'not',\n",
       " 'show',\n",
       " 'St.',\n",
       " 'Amant',\n",
       " 'acted',\n",
       " 'with',\n",
       " '“',\n",
       " 'malice.',\n",
       " '”',\n",
       " 'Thompson',\n",
       " 'then',\n",
       " 'appealed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Supreme',\n",
       " 'Court',\n",
       " 'of',\n",
       " 'Louisiana',\n",
       " '.',\n",
       " 'That',\n",
       " 'court',\n",
       " 'held',\n",
       " 'that',\n",
       " ',',\n",
       " 'although',\n",
       " 'public',\n",
       " 'figures',\n",
       " 'forfeit',\n",
       " 'some',\n",
       " 'of',\n",
       " 'their',\n",
       " 'First',\n",
       " 'Amendment',\n",
       " 'protection',\n",
       " 'from',\n",
       " 'defamation',\n",
       " ',',\n",
       " 'St.',\n",
       " 'Amant',\n",
       " 'accused',\n",
       " 'Thompson',\n",
       " 'of',\n",
       " 'a',\n",
       " 'crime',\n",
       " 'with',\n",
       " 'utter',\n",
       " 'disregard',\n",
       " 'of',\n",
       " 'whether',\n",
       " 'the',\n",
       " 'remarks',\n",
       " 'were',\n",
       " 'true',\n",
       " '.',\n",
       " 'Finally',\n",
       " ',',\n",
       " 'that',\n",
       " 'court',\n",
       " 'held',\n",
       " 'that',\n",
       " 'the',\n",
       " 'First',\n",
       " 'Amendment',\n",
       " 'protects',\n",
       " 'uninhibited',\n",
       " ',',\n",
       " 'robust',\n",
       " 'debate',\n",
       " ',',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'an',\n",
       " 'open',\n",
       " 'season',\n",
       " 'to',\n",
       " 'shoot',\n",
       " 'down',\n",
       " 'the',\n",
       " 'good',\n",
       " 'name',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'who',\n",
       " 'happens',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'public',\n",
       " 'servant',\n",
       " '.',\n",
       " 'Ramon',\n",
       " 'Nelson',\n",
       " 'was',\n",
       " 'riding',\n",
       " 'his',\n",
       " 'bike',\n",
       " 'when',\n",
       " 'he',\n",
       " 'suffered',\n",
       " 'a',\n",
       " 'lethal',\n",
       " 'blow',\n",
       " 'to',\n",
       " 'the',\n",
       " 'back',\n",
       " 'of',\n",
       " 'his',\n",
       " 'head',\n",
       " 'with',\n",
       " 'a',\n",
       " 'baseball',\n",
       " 'bat',\n",
       " '.',\n",
       " 'After',\n",
       " 'two',\n",
       " 'eyewitnesses',\n",
       " 'identified',\n",
       " 'Lawrence',\n",
       " 'Owens',\n",
       " 'from',\n",
       " 'an',\n",
       " 'array',\n",
       " 'of',\n",
       " 'photos',\n",
       " 'and',\n",
       " 'then',\n",
       " 'a',\n",
       " 'lineup',\n",
       " ',',\n",
       " 'he',\n",
       " 'was',\n",
       " 'tried',\n",
       " 'and',\n",
       " 'convicted',\n",
       " 'for',\n",
       " 'Nelson',\n",
       " '’',\n",
       " 's',\n",
       " 'death',\n",
       " '.',\n",
       " 'Because',\n",
       " 'Nelson',\n",
       " 'was',\n",
       " 'carrying',\n",
       " 'cocaine',\n",
       " 'and',\n",
       " 'crack',\n",
       " 'cocaine',\n",
       " 'potentially',\n",
       " 'for',\n",
       " 'distribution',\n",
       " ',',\n",
       " 'the',\n",
       " 'judge',\n",
       " 'at',\n",
       " 'Owens',\n",
       " '’',\n",
       " 'bench',\n",
       " 'trial',\n",
       " 'ruled',\n",
       " 'that',\n",
       " 'Owens',\n",
       " 'was',\n",
       " 'probably',\n",
       " 'also',\n",
       " 'a',\n",
       " 'drug',\n",
       " 'dealer',\n",
       " 'and',\n",
       " 'was',\n",
       " 'trying',\n",
       " 'to',\n",
       " '“',\n",
       " 'knock',\n",
       " '[',\n",
       " 'Nelson',\n",
       " ']',\n",
       " 'off.',\n",
       " '”',\n",
       " 'Owens',\n",
       " 'was',\n",
       " 'found',\n",
       " 'guilty',\n",
       " 'of',\n",
       " 'first-degree',\n",
       " 'murder',\n",
       " 'and',\n",
       " 'sentenced',\n",
       " 'to',\n",
       " '25',\n",
       " 'years',\n",
       " 'in',\n",
       " 'prison',\n",
       " '.',\n",
       " 'Owens',\n",
       " 'filed',\n",
       " 'a',\n",
       " 'petition',\n",
       " 'for',\n",
       " 'a',\n",
       " 'writ',\n",
       " 'of',\n",
       " 'habeas',\n",
       " 'corpus',\n",
       " 'on',\n",
       " 'the',\n",
       " 'grounds',\n",
       " 'that',\n",
       " 'his',\n",
       " 'constitutional',\n",
       " 'right',\n",
       " 'to',\n",
       " 'due',\n",
       " 'process',\n",
       " 'was',\n",
       " 'violated',\n",
       " 'during',\n",
       " 'the',\n",
       " 'trial',\n",
       " '.',\n",
       " 'He',\n",
       " 'argued',\n",
       " 'that',\n",
       " 'the',\n",
       " 'eyewitness',\n",
       " 'identification',\n",
       " 'should',\n",
       " 'have',\n",
       " 'been',\n",
       " 'inadmissible',\n",
       " 'based',\n",
       " 'on',\n",
       " 'unreliability',\n",
       " 'and',\n",
       " 'that',\n",
       " 'the',\n",
       " 'judge',\n",
       " 'impermissibly',\n",
       " 'inferred',\n",
       " 'a',\n",
       " 'motive',\n",
       " 'when',\n",
       " 'a',\n",
       " 'motive',\n",
       " 'was',\n",
       " 'not',\n",
       " 'an',\n",
       " 'element',\n",
       " 'of',\n",
       " 'the',\n",
       " 'offense',\n",
       " '.',\n",
       " 'The',\n",
       " 'district',\n",
       " 'court',\n",
       " 'denied',\n",
       " 'the',\n",
       " 'writ',\n",
       " 'of',\n",
       " 'habeas',\n",
       " 'corpus',\n",
       " ',',\n",
       " 'and',\n",
       " 'Owens',\n",
       " 'appealed',\n",
       " '.',\n",
       " 'The',\n",
       " 'U.S.',\n",
       " 'Court',\n",
       " 'of',\n",
       " 'Appeals',\n",
       " 'for',\n",
       " 'the',\n",
       " 'Seventh',\n",
       " 'Circuit',\n",
       " 'reversed',\n",
       " 'the',\n",
       " 'denial',\n",
       " 'and',\n",
       " 'held',\n",
       " 'that',\n",
       " 'the',\n",
       " 'trial',\n",
       " 'judge',\n",
       " '’',\n",
       " 's',\n",
       " 'inference',\n",
       " 'about',\n",
       " 'Owens',\n",
       " '’',\n",
       " 's',\n",
       " 'motive',\n",
       " 'violated',\n",
       " 'his',\n",
       " 'right',\n",
       " 'to',\n",
       " 'have',\n",
       " 'his',\n",
       " 'guilt',\n",
       " 'adjudicated',\n",
       " 'solely',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'evidence',\n",
       " 'presented',\n",
       " 'at',\n",
       " 'trial',\n",
       " '.',\n",
       " 'An',\n",
       " 'Alabama',\n",
       " 'state',\n",
       " 'court',\n",
       " 'convicted',\n",
       " 'Billy',\n",
       " 'Joe',\n",
       " 'Magwood',\n",
       " 'of',\n",
       " 'murder',\n",
       " 'and',\n",
       " 'sentenced',\n",
       " 'him',\n",
       " 'to',\n",
       " 'death',\n",
       " '.',\n",
       " 'Subsequently',\n",
       " ',',\n",
       " 'an',\n",
       " 'Alabama',\n",
       " 'federal',\n",
       " 'district',\n",
       " 'court',\n",
       " 'partially',\n",
       " 'granted',\n",
       " 'Mr.',\n",
       " 'Magwood',\n",
       " \"'s\",\n",
       " 'petition',\n",
       " 'for',\n",
       " 'federal',\n",
       " 'habeas',\n",
       " 'corpus',\n",
       " 'relief',\n",
       " '.',\n",
       " 'The',\n",
       " 'court',\n",
       " 'upheld',\n",
       " 'his',\n",
       " 'conviction',\n",
       " 'but',\n",
       " 'instructed',\n",
       " 'the',\n",
       " 'state',\n",
       " 'court',\n",
       " 'to',\n",
       " 'look',\n",
       " 'at',\n",
       " 'mitigating',\n",
       " 'evidence',\n",
       " 'when',\n",
       " 'resentencing',\n",
       " 'Mr.',\n",
       " 'Magwood',\n",
       " '.',\n",
       " 'Upon',\n",
       " 'resentencing',\n",
       " ',',\n",
       " 'the',\n",
       " 'state',\n",
       " 'court',\n",
       " 'sentenced',\n",
       " 'Mr.',\n",
       " 'Magwood',\n",
       " 'to',\n",
       " 'death',\n",
       " 'once',\n",
       " 'again',\n",
       " '.',\n",
       " 'Mr.',\n",
       " 'Magwood',\n",
       " 'filed',\n",
       " 'a',\n",
       " 'second',\n",
       " 'petition',\n",
       " 'for',\n",
       " 'federal',\n",
       " 'habeas',\n",
       " 'corpus',\n",
       " 'relief',\n",
       " 'with',\n",
       " 'the',\n",
       " 'federal',\n",
       " 'district',\n",
       " 'court',\n",
       " 'arguing',\n",
       " 'that',\n",
       " 'a',\n",
       " 'judicial',\n",
       " 'rule',\n",
       " 'was',\n",
       " 'retroactively',\n",
       " 'applied',\n",
       " 'in',\n",
       " 'his',\n",
       " 'case',\n",
       " 'and',\n",
       " 'that',\n",
       " 'he',\n",
       " 'lacked',\n",
       " 'effective',\n",
       " 'counsel',\n",
       " 'at',\n",
       " 'sentencing',\n",
       " '.',\n",
       " 'The',\n",
       " 'district',\n",
       " 'court',\n",
       " 'granted',\n",
       " 'the',\n",
       " 'petition',\n",
       " 'and',\n",
       " 'vacated',\n",
       " 'Mr.',\n",
       " 'Magwood',\n",
       " \"'s\",\n",
       " 'death',\n",
       " 'sentence',\n",
       " '.',\n",
       " 'On',\n",
       " 'appeal',\n",
       " ',',\n",
       " 'the',\n",
       " 'U.S.',\n",
       " 'Court',\n",
       " 'of',\n",
       " 'Appeals',\n",
       " 'for',\n",
       " 'the',\n",
       " 'Eleventh',\n",
       " 'circuit',\n",
       " 'reversed',\n",
       " ',',\n",
       " 'holding',\n",
       " 'that',\n",
       " 'prisoners',\n",
       " 'may',\n",
       " 'not',\n",
       " 'raise',\n",
       " 'challenges',\n",
       " 'to',\n",
       " 'an',\n",
       " 'original',\n",
       " 'sentence',\n",
       " 'that',\n",
       " 'could',\n",
       " 'have',\n",
       " 'been',\n",
       " 'raised',\n",
       " 'in',\n",
       " 'an',\n",
       " 'earlier',\n",
       " 'petition',\n",
       " '.',\n",
       " 'The',\n",
       " 'court',\n",
       " 'also',\n",
       " 'held',\n",
       " 'that',\n",
       " 'Mr.',\n",
       " 'Magwood',\n",
       " \"'s\",\n",
       " 'counsel',\n",
       " 'was',\n",
       " 'not',\n",
       " 'ineffective',\n",
       " 'because',\n",
       " 'he',\n",
       " 'failed',\n",
       " 'to',\n",
       " 'raise',\n",
       " 'an',\n",
       " 'argument',\n",
       " 'that',\n",
       " 'had',\n",
       " 'already',\n",
       " 'been',\n",
       " 'decided',\n",
       " 'by',\n",
       " 'the',\n",
       " 'state',\n",
       " \"'s\",\n",
       " 'highest',\n",
       " 'court',\n",
       " 'adverse',\n",
       " 'to',\n",
       " 'his',\n",
       " 'client',\n",
       " \"'s\",\n",
       " 'position',\n",
       " '.',\n",
       " 'Victor',\n",
       " 'Linkletter',\n",
       " 'was',\n",
       " 'convicted',\n",
       " 'in',\n",
       " 'state',\n",
       " 'court',\n",
       " 'on',\n",
       " 'evidence',\n",
       " 'illegally',\n",
       " 'obtained',\n",
       " 'by',\n",
       " 'police',\n",
       " 'prior',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Supreme',\n",
       " 'Court',\n",
       " 'decision',\n",
       " 'concerning',\n",
       " 'the',\n",
       " 'Fourth',\n",
       " 'Amendment',\n",
       " 'in',\n",
       " 'Mapp',\n",
       " 'v.',\n",
       " 'Ohio',\n",
       " '.',\n",
       " 'Mapp',\n",
       " 'applied',\n",
       " 'the',\n",
       " 'exclusionary',\n",
       " 'rule',\n",
       " 'to',\n",
       " 'state',\n",
       " 'criminal',\n",
       " 'proceedings',\n",
       " ',',\n",
       " 'denying',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'illegally',\n",
       " 'obtained',\n",
       " 'evidence',\n",
       " 'at',\n",
       " 'trial',\n",
       " '.',\n",
       " 'Linkletter',\n",
       " 'argued',\n",
       " 'for',\n",
       " 'a',\n",
       " 'retrial',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Mapp',\n",
       " 'decision',\n",
       " '.',\n",
       " 'On',\n",
       " 'April',\n",
       " '24',\n",
       " ',',\n",
       " '1953',\n",
       " 'in',\n",
       " 'Selma',\n",
       " ',',\n",
       " 'Alabama',\n",
       " ',',\n",
       " 'an',\n",
       " 'intruder',\n",
       " 'broke',\n",
       " 'into',\n",
       " 'the',\n",
       " 'apartment',\n",
       " 'of',\n",
       " 'the',\n",
       " 'daughter',\n",
       " 'of',\n",
       " 'the',\n",
       " 'city',\n",
       " 'mayor',\n",
       " '.',\n",
       " 'The',\n",
       " 'daughter',\n",
       " 'and',\n",
       " 'the',\n",
       " 'intruder',\n",
       " 'struggled',\n",
       " 'through',\n",
       " 'several',\n",
       " 'rooms',\n",
       " 'until',\n",
       " 'she',\n",
       " 'was',\n",
       " 'able',\n",
       " 'to',\n",
       " 'seize',\n",
       " 'his',\n",
       " 'knife',\n",
       " ',',\n",
       " 'and',\n",
       " 'he',\n",
       " 'fled',\n",
       " '.',\n",
       " 'The',\n",
       " 'assailant',\n",
       " 'had',\n",
       " 'a',\n",
       " 'towel',\n",
       " 'over',\n",
       " 'his',\n",
       " 'head',\n",
       " ',',\n",
       " 'so',\n",
       " 'the',\n",
       " 'victim',\n",
       " 'could',\n",
       " 'not',\n",
       " 'identify',\n",
       " 'the',\n",
       " 'defendant',\n",
       " 'during',\n",
       " 'the',\n",
       " 'trial',\n",
       " '.',\n",
       " 'The',\n",
       " 'police',\n",
       " 'apprehended',\n",
       " 'William',\n",
       " 'Earl',\n",
       " 'Fikes',\n",
       " 'on',\n",
       " 'the',\n",
       " 'basis',\n",
       " 'of',\n",
       " 'a',\n",
       " 'call',\n",
       " 'from',\n",
       " 'a',\n",
       " 'private',\n",
       " 'citizen',\n",
       " 'and',\n",
       " 'held',\n",
       " 'him',\n",
       " '“',\n",
       " 'on',\n",
       " 'an',\n",
       " 'open',\n",
       " 'charge',\n",
       " 'of',\n",
       " 'investigation.',\n",
       " '”',\n",
       " 'The',\n",
       " 'police',\n",
       " 'questioned',\n",
       " 'Fikes',\n",
       " 'for',\n",
       " 'hours',\n",
       " ',',\n",
       " 'placed',\n",
       " 'him',\n",
       " 'in',\n",
       " 'jail',\n",
       " ',',\n",
       " 'and',\n",
       " 'limited',\n",
       " 'his',\n",
       " 'access',\n",
       " 'to',\n",
       " 'anyone',\n",
       " 'familiar',\n",
       " '.',\n",
       " 'After',\n",
       " 'nearly',\n",
       " 'a',\n",
       " 'week',\n",
       " 'of',\n",
       " 'this',\n",
       " 'treatment',\n",
       " ',',\n",
       " 'Fikes',\n",
       " 'confessed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'form',\n",
       " 'of',\n",
       " 'answers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'interrogator',\n",
       " '’',\n",
       " 's',\n",
       " 'leading',\n",
       " 'questions',\n",
       " '.',\n",
       " 'Five',\n",
       " 'days',\n",
       " 'later',\n",
       " ',',\n",
       " 'Fikes',\n",
       " 'confessed',\n",
       " 'under',\n",
       " 'questioning',\n",
       " 'a',\n",
       " 'second',\n",
       " 'time',\n",
       " '.',\n",
       " 'When',\n",
       " 'these',\n",
       " 'confessions',\n",
       " 'were',\n",
       " 'admitted',\n",
       " 'into',\n",
       " 'the',\n",
       " 'trial',\n",
       " 'as',\n",
       " 'evidence',\n",
       " ',',\n",
       " 'Fikes',\n",
       " 'did',\n",
       " 'not',\n",
       " 'testify',\n",
       " 'regarding',\n",
       " 'the',\n",
       " 'events',\n",
       " 'surrounding',\n",
       " 'his',\n",
       " 'interrogation',\n",
       " 'because',\n",
       " 'the',\n",
       " 'judge',\n",
       " 'had',\n",
       " 'ruled',\n",
       " 'he',\n",
       " 'would',\n",
       " 'be',\n",
       " 'subjected',\n",
       " 'to',\n",
       " 'unlimited',\n",
       " 'cross-examination',\n",
       " '.',\n",
       " 'The',\n",
       " 'jury',\n",
       " 'convicted',\n",
       " 'Fikes',\n",
       " 'and',\n",
       " 'sentenced',\n",
       " 'him',\n",
       " 'to',\n",
       " 'death',\n",
       " '.',\n",
       " 'The',\n",
       " 'Supreme',\n",
       " 'Court',\n",
       " 'of',\n",
       " 'Alabama',\n",
       " 'affirmed',\n",
       " '.',\n",
       " 'A',\n",
       " 'New',\n",
       " 'York',\n",
       " 'town',\n",
       " ',',\n",
       " 'Clarkstown',\n",
       " ',',\n",
       " 'allowed',\n",
       " 'a',\n",
       " 'contractor',\n",
       " 'to',\n",
       " 'construct',\n",
       " 'and',\n",
       " 'operate',\n",
       " 'a',\n",
       " 'waste',\n",
       " 'processing',\n",
       " 'plant',\n",
       " 'within',\n",
       " 'town',\n",
       " 'limits',\n",
       " '.',\n",
       " 'The',\n",
       " 'revenue',\n",
       " 'from',\n",
       " 'the',\n",
       " 'plant',\n",
       " 'would',\n",
       " 'help',\n",
       " 'compensate',\n",
       " 'the',\n",
       " 'contractor',\n",
       " '.',\n",
       " 'Clarkstown',\n",
       " 'promised',\n",
       " 'that',\n",
       " 'the',\n",
       " 'plant',\n",
       " 'would',\n",
       " 'receive',\n",
       " '120,000',\n",
       " 'tons',\n",
       " 'of',\n",
       " 'solid',\n",
       " 'waste',\n",
       " 'each',\n",
       " 'year',\n",
       " ',',\n",
       " 'and',\n",
       " 'permitted',\n",
       " 'the',\n",
       " 'contractor',\n",
       " 'to',\n",
       " 'charge',\n",
       " 'an',\n",
       " '$',\n",
       " '81',\n",
       " '``',\n",
       " 'tipping',\n",
       " 'fee',\n",
       " \"''\",\n",
       " 'for',\n",
       " 'each',\n",
       " 'ton',\n",
       " 'received',\n",
       " '.',\n",
       " 'To',\n",
       " 'meet',\n",
       " 'the',\n",
       " '120,000',\n",
       " 'ton',\n",
       " 'quota',\n",
       " ',',\n",
       " 'Clarkstown',\n",
       " 'adopted',\n",
       " 'a',\n",
       " '``',\n",
       " 'flow',\n",
       " 'control',\n",
       " 'ordinance',\n",
       " '.',\n",
       " \"''\",\n",
       " 'The',\n",
       " 'ordinance',\n",
       " 'required',\n",
       " 'that',\n",
       " 'all',\n",
       " 'solid',\n",
       " 'waste',\n",
       " 'flowing',\n",
       " 'into',\n",
       " 'and',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'town',\n",
       " 'pass',\n",
       " 'through',\n",
       " 'the',\n",
       " 'new',\n",
       " 'plant',\n",
       " '.',\n",
       " 'C',\n",
       " '&',\n",
       " 'A',\n",
       " 'Carbone',\n",
       " ',',\n",
       " 'Inc.',\n",
       " 'operated',\n",
       " 'a',\n",
       " 'similar',\n",
       " 'plant',\n",
       " 'within',\n",
       " 'the',\n",
       " 'town',\n",
       " '.',\n",
       " 'To',\n",
       " 'avoid',\n",
       " 'paying',\n",
       " 'the',\n",
       " '$',\n",
       " '81',\n",
       " 'fee',\n",
       " ',',\n",
       " 'Carbone',\n",
       " 'trucked',\n",
       " 'processed',\n",
       " 'waste',\n",
       " 'directly',\n",
       " 'to',\n",
       " ...]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df_nlp1['facts']\n",
    "# print(corpus.str.cat(sep=\" \")) # 인덱스의 요소들 서로 잇기\n",
    "lst_tokens = nltk.tokenize.word_tokenize(corpus.str.cat(sep=\" \"))\n",
    "lst_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.stem.porter.PorterStemmer()\n",
    "lem = nltk.stem.wordnet.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    import re\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp1[\"facts_clean\"] = df_nlp1[\"facts\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=lst_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp2 = pd.concat([df_nlp1,df_target['first_party_winner']],axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facts</th>\n",
       "      <th>facts_clean</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
       "      <td>june 27 1962 phil st amant candidate public of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
       "      <td>ramon nelson riding bike suffered lethal blow ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
       "      <td>alabama state court convicted billy joe magwoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Victor Linkletter was convicted in state court...</td>\n",
       "      <td>victor linkletter convicted state court eviden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
       "      <td>april 24 1953 selma alabama intruder broke apa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>Congress amended the Clean Air Act through the...</td>\n",
       "      <td>congress amended clean air act energy policy a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>Alliance Bond Fund, Inc., an investment fund, ...</td>\n",
       "      <td>alliance bond fund inc investment fund purchas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>In 1992, the District Court sentenced Manuel D...</td>\n",
       "      <td>1992 district court sentenced manuel peguero 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>On March 8, 1996, Enrico St. Cyr, a lawful per...</td>\n",
       "      <td>march 8 1996 enrico st cyr lawful permanent re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>Herbert Markman owns the patent to a system th...</td>\n",
       "      <td>herbert markman owns patent system track cloth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  facts  \\\n",
       "0     On June 27, 1962, Phil St. Amant, a candidate ...   \n",
       "1     Ramon Nelson was riding his bike when he suffe...   \n",
       "2     An Alabama state court convicted Billy Joe Mag...   \n",
       "3     Victor Linkletter was convicted in state court...   \n",
       "4     On April 24, 1953 in Selma, Alabama, an intrud...   \n",
       "...                                                 ...   \n",
       "2473  Congress amended the Clean Air Act through the...   \n",
       "2474  Alliance Bond Fund, Inc., an investment fund, ...   \n",
       "2475  In 1992, the District Court sentenced Manuel D...   \n",
       "2476  On March 8, 1996, Enrico St. Cyr, a lawful per...   \n",
       "2477  Herbert Markman owns the patent to a system th...   \n",
       "\n",
       "                                            facts_clean  first_party_winner  \n",
       "0     june 27 1962 phil st amant candidate public of...                   1  \n",
       "1     ramon nelson riding bike suffered lethal blow ...                   0  \n",
       "2     alabama state court convicted billy joe magwoo...                   1  \n",
       "3     victor linkletter convicted state court eviden...                   0  \n",
       "4     april 24 1953 selma alabama intruder broke apa...                   1  \n",
       "...                                                 ...                 ...  \n",
       "2473  congress amended clean air act energy policy a...                   1  \n",
       "2474  alliance bond fund inc investment fund purchas...                   1  \n",
       "2475  1992 district court sentenced manuel peguero 2...                   0  \n",
       "2476  march 8 1996 enrico st cyr lawful permanent re...                   0  \n",
       "2477  herbert markman owns patent system track cloth...                   0  \n",
       "\n",
       "[2478 rows x 3 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp2 = pd.concat([df_nlp1,df_target['first_party_winner']],axis=1, join='inner')\n",
    "df_nlp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest[\"facts_clean\"] = dfTest[\"facts\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=lst_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df_nlp2['facts_clean']\n",
    "# y_train = df_nlp2['first_party_winner']\n",
    "\n",
    "# X_test = dfTest['facts_clean']\n",
    "dfTest['first_party_winner'] = np.zeros(len(dfTest)).astype(int)\n",
    "# y_test = dfTest['first_party_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfeatures = df_nlp2['facts_clean']\n",
    "ylabel = df_nlp2['first_party_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xfeatures,ylabel, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('cv',CountVectorizer()),('lr',LogisticRegression(solver='liblinear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer()),\n",
       "                (&#x27;lr&#x27;, LogisticRegression(solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer()),\n",
       "                (&#x27;lr&#x27;, LogisticRegression(solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer()),\n",
       "                ('lr', LogisticRegression(solver='liblinear'))])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1= Pipeline(steps=[('cv',CountVectorizer()),('rf',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer()), (&#x27;rf&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer()), (&#x27;rf&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer()), ('rf', RandomForestClassifier())])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6935483870967742"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2= Pipeline(steps=[('cv',CountVectorizer()),('rf',KNeighborsClassifier(n_neighbors=3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer()),\n",
       "                (&#x27;rf&#x27;, KNeighborsClassifier(n_neighbors=3))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cv&#x27;, CountVectorizer()),\n",
       "                (&#x27;rf&#x27;, KNeighborsClassifier(n_neighbors=3))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer()),\n",
       "                ('rf', KNeighborsClassifier(n_neighbors=3))])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8697524219590959"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6661290322580645"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>011119</th>\n",
       "      <th>0125</th>\n",
       "      <th>02</th>\n",
       "      <th>036539</th>\n",
       "      <th>04</th>\n",
       "      <th>041352</th>\n",
       "      <th>041581</th>\n",
       "      <th>0479</th>\n",
       "      <th>05</th>\n",
       "      <th>0511287</th>\n",
       "      <th>...</th>\n",
       "      <th>zj</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoned</th>\n",
       "      <th>zoneofinterests</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zubik</th>\n",
       "      <th>zuni</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zurko</th>\n",
       "      <th>zurkos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 17985 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      011119  0125  02  036539  04  041352  041581  0479  05  0511287  ...  \\\n",
       "0          0     0   0       0   0       0       0     0   0        0  ...   \n",
       "1          0     0   0       0   0       0       0     0   0        0  ...   \n",
       "2          0     0   0       0   0       0       0     0   0        0  ...   \n",
       "3          0     0   0       0   0       0       0     0   0        0  ...   \n",
       "4          0     0   0       0   0       0       0     0   0        0  ...   \n",
       "...      ...   ...  ..     ...  ..     ...     ...   ...  ..      ...  ...   \n",
       "2473       0     0   0       0   0       0       0     0   0        0  ...   \n",
       "2474       0     0   0       0   0       0       0     0   0        0  ...   \n",
       "2475       0     0   0       0   0       0       0     0   0        0  ...   \n",
       "2476       0     0   0       0   0       0       0     0   0        0  ...   \n",
       "2477       0     0   0       0   0       0       0     0   0        0  ...   \n",
       "\n",
       "      zj  zone  zoned  zoneofinterests  zoning  zubik  zuni  zurich  zurko  \\\n",
       "0      0     0      0                0       0      0     0       0      0   \n",
       "1      0     0      0                0       0      0     0       0      0   \n",
       "2      0     0      0                0       0      0     0       0      0   \n",
       "3      0     0      0                0       0      0     0       0      0   \n",
       "4      0     0      0                0       0      0     0       0      0   \n",
       "...   ..   ...    ...              ...     ...    ...   ...     ...    ...   \n",
       "2473   0     0      0                0       0      0     0       0      0   \n",
       "2474   0     0      0                0       0      0     0       0      0   \n",
       "2475   0     0      0                0       0      0     0       0      0   \n",
       "2476   0     0      0                0       0      0     0       0      0   \n",
       "2477   0     0      0                0       0      0     0       0      0   \n",
       "\n",
       "      zurkos  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "2473       0  \n",
       "2474       0  \n",
       "2475       0  \n",
       "2476       0  \n",
       "2477       0  \n",
       "\n",
       "[2478 rows x 17985 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix = vectorize.fit_transform(df_nlp2['facts_clean'])\n",
    "count_array = count_matrix.toarray()\n",
    "data_final = pd.DataFrame(data=count_array,columns = vectorize.get_feature_names_out())\n",
    "data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.concat([data_final,df_nlp2[\"first_party_winner\"]],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>011119</th>\n",
       "      <th>04</th>\n",
       "      <th>041581</th>\n",
       "      <th>0479</th>\n",
       "      <th>05</th>\n",
       "      <th>07394</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>...</th>\n",
       "      <th>zita</th>\n",
       "      <th>zivotofsky</th>\n",
       "      <th>zivotofskys</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoned</th>\n",
       "      <th>zoneofinterests</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zuni</th>\n",
       "      <th>zurich</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows × 8458 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     011119  04  041581  0479  05  07394  10  100  1000  10000  ...  zita  \\\n",
       "0         0   0       0     0   0      0   0    0     0      0  ...     0   \n",
       "1         0   0       0     0   0      0   0    0     0      0  ...     0   \n",
       "2         0   0       0     0   0      0   0    0     0      0  ...     0   \n",
       "3         0   0       0     0   0      0   0    0     0      0  ...     0   \n",
       "4         0   0       0     0   0      0   0    0     0      0  ...     0   \n",
       "..      ...  ..     ...   ...  ..    ...  ..  ...   ...    ...  ...   ...   \n",
       "615       0   0       0     0   0      0   0    0     0      0  ...     0   \n",
       "616       0   0       0     0   0      0   0    0     0      0  ...     0   \n",
       "617       0   0       0     0   0      0   0    0     0      0  ...     0   \n",
       "618       0   0       0     0   0      0   0    0     0      0  ...     0   \n",
       "619       0   0       0     0   0      0   0    0     0      0  ...     0   \n",
       "\n",
       "     zivotofsky  zivotofskys  zone  zoned  zoneofinterests  zoning  zuni  \\\n",
       "0             0            0     0      0                0       0     0   \n",
       "1             0            0     0      0                0       0     0   \n",
       "2             0            0     0      0                0       0     0   \n",
       "3             0            0     0      0                0       0     0   \n",
       "4             0            0     0      0                0       0     0   \n",
       "..          ...          ...   ...    ...              ...     ...   ...   \n",
       "615           0            0     0      0                0       0     0   \n",
       "616           0            0     0      0                0       0     0   \n",
       "617           0            0     0      0                0       0     0   \n",
       "618           0            0     0      0                0       0     0   \n",
       "619           0            0     0      0                0       0     0   \n",
       "\n",
       "     zurich  first_party_winner  \n",
       "0         0                   0  \n",
       "1         0                   0  \n",
       "2         0                   0  \n",
       "3         0                   0  \n",
       "4         0                   0  \n",
       "..      ...                 ...  \n",
       "615       0                   0  \n",
       "616       0                   0  \n",
       "617       0                   0  \n",
       "618       0                   0  \n",
       "619       0                   0  \n",
       "\n",
       "[620 rows x 8458 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix = vectorize.fit_transform(X_test)\n",
    "count_array = count_matrix.toarray()\n",
    "data_final_test = pd.DataFrame(data=count_array,columns = vectorize.get_feature_names_out())\n",
    "data_final_test = pd.concat([data_final_test,dfTest[\"first_party_winner\"]],axis=1,join='inner')\n",
    "data_final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = data_final.drop(columns=['first_party_winner'])\n",
    "# y_train = data_final['first_party_winner']\n",
    "\n",
    "X_test = data_final_test.drop(columns=['first_party_winner'])\n",
    "y_test = data_final_test['first_party_winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(data_final.drop(columns=['first_party_winner']), data_final['first_party_winner'], test_size=0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_final = scaler.fit_transform(data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components=200, random_state=0)\n",
    "lda_data = lda.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_data_train = pd.DataFrame(data=lda_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- 0125\n- 02\n- 036539\n- 041352\n- 0511287\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lda_data_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mlda\u001b[39m.\u001b[39mtransform(X_test))\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\py\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\py\\Lib\\site-packages\\sklearn\\decomposition\\_lda.py:738\u001b[0m, in \u001b[0;36mLatentDirichletAllocation.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform data X according to the fitted model.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \n\u001b[0;32m    724\u001b[0m \u001b[39m   .. versionchanged:: 0.18\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[39m    Document topic distribution for X.\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    737\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 738\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_non_neg_array(\n\u001b[0;32m    739\u001b[0m     X, reset_n_features\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, whom\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLatentDirichletAllocation.transform\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    740\u001b[0m )\n\u001b[0;32m    741\u001b[0m doc_topic_distr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unnormalized_transform(X)\n\u001b[0;32m    742\u001b[0m doc_topic_distr \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m doc_topic_distr\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[:, np\u001b[39m.\u001b[39mnewaxis]\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\py\\Lib\\site-packages\\sklearn\\decomposition\\_lda.py:561\u001b[0m, in \u001b[0;36mLatentDirichletAllocation._check_non_neg_array\u001b[1;34m(self, X, reset_n_features, whom)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"check X format\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \n\u001b[0;32m    552\u001b[0m \u001b[39mcheck X format and make sure no negative value in X.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    557\u001b[0m \n\u001b[0;32m    558\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    559\u001b[0m dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32] \u001b[39mif\u001b[39;00m reset_n_features \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponents_\u001b[39m.\u001b[39mdtype\n\u001b[1;32m--> 561\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[0;32m    562\u001b[0m     X,\n\u001b[0;32m    563\u001b[0m     reset\u001b[39m=\u001b[39mreset_n_features,\n\u001b[0;32m    564\u001b[0m     accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    565\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    566\u001b[0m )\n\u001b[0;32m    567\u001b[0m check_non_negative(X, whom)\n\u001b[0;32m    569\u001b[0m \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\py\\Lib\\site-packages\\sklearn\\base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[0;32m    490\u001b[0m ):\n\u001b[0;32m    491\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \n\u001b[0;32m    493\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_names(X, reset\u001b[39m=\u001b[39mreset)\n\u001b[0;32m    550\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    551\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    552\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    554\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\py\\Lib\\site-packages\\sklearn\\base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    477\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    478\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    479\u001b[0m     )\n\u001b[1;32m--> 481\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- 0125\n- 02\n- 036539\n- 041352\n- 0511287\n- ...\n"
     ]
    }
   ],
   "source": [
    "lda_data_test = pd.DataFrame(data=lda.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand=RandomForestClassifier(max_depth= 8, max_features = 100, min_samples_leaf = 2, n_estimators = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=8, max_features=100, min_samples_leaf=2,\n",
       "                       n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=8, max_features=100, min_samples_leaf=2,\n",
       "                       n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=8, max_features=100, min_samples_leaf=2,\n",
       "                       n_estimators=200)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.fit(lda_data_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7093425605536332"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.score(lda_data_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6397849462365591"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.score(lda_data_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7766666666666667"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = rand.predict(lda_data_test)\n",
    "f1_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [620, 744]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m predictions \u001b[39m=\u001b[39m [\u001b[39mround\u001b[39m(value) \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m y_pred]\n\u001b[0;32m      5\u001b[0m \u001b[39m# evaluate predictions\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, predictions)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m%%\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (accuracy \u001b[39m*\u001b[39m \u001b[39m100.0\u001b[39m))\n\u001b[0;32m      8\u001b[0m f1_score(y_test, y_pred1)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\py\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    199\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\py\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\py\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     87\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\py\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [620, 744]"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(lda_data_train, y_train)\n",
    "y_pred = model.predict(lda_data_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "f1_score(y_test, y_pred1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" checked><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(lda_data_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7249134948096886"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(lda_data_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6075268817204301"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(lda_data_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "submit = pd.read_csv('C:/data/project/sample_submission.csv')\n",
    "predcsv = pd.DataFrame(predictions,columns=['first_party_winner'])\n",
    "# submit['first_party_winner'] = predictions\n",
    "# predcsv\n",
    "submit['first_party_winner'] = predcsv\n",
    "submit.to_csv('./baseline_submit.csv', index=False)\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
