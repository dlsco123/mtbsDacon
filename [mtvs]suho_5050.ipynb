{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리내 변수 제거\n",
    "\n",
    "all = [var for var in globals() if var[0] != \"_\"]   # globals() 목록의 첫글자가 _ 로 시작하지 않는 자료의 리스트만 가져와서\n",
    "for var in all:\n",
    "    del globals()[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install xgboost\n",
    "#%pip install wordcloud\n",
    "#%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "## for data\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk## for language detection\n",
    "\n",
    "# 박스 출력\n",
    "import textwrap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>Phil A. St. Amant</td>\n",
       "      <td>Herman A. Thompson</td>\n",
       "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Stephen Duncan</td>\n",
       "      <td>Lawrence Owens</td>\n",
       "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>Billy Joe Magwood</td>\n",
       "      <td>Tony Patterson, Warden, et al.</td>\n",
       "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Linkletter</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Victor Linkletter was convicted in state court...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>William Earl Fikes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID         first_party                    second_party  \\\n",
       "0  TRAIN_0000   Phil A. St. Amant              Herman A. Thompson   \n",
       "1  TRAIN_0001      Stephen Duncan                  Lawrence Owens   \n",
       "2  TRAIN_0002   Billy Joe Magwood  Tony Patterson, Warden, et al.   \n",
       "3  TRAIN_0003          Linkletter                          Walker   \n",
       "4  TRAIN_0004  William Earl Fikes                         Alabama   \n",
       "\n",
       "                                               facts  first_party_winner  \n",
       "0  On June 27, 1962, Phil St. Amant, a candidate ...                   1  \n",
       "1  Ramon Nelson was riding his bike when he suffe...                   0  \n",
       "2  An Alabama state court convicted Billy Joe Mag...                   1  \n",
       "3  Victor Linkletter was convicted in state court...                   0  \n",
       "4  On April 24, 1953 in Selma, Alabama, an intrud...                   1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('c:/data/project/train.csv')\n",
    "test = pd.read_csv('c:/data/project/test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_party_winner\n",
       "1    1649\n",
       "0     829\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['first_party_winner'].value_counts()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 체크 함수인데, 사용하지 않아도 됨. 참고용 셀\n",
    "\n",
    "def jungbokCheck():\n",
    "    df = train.drop(columns='ID')\n",
    "    f_label = df['first_party'].unique() # 한 칼럼의 구성요소들이 서로 중복되지 않게 하기(pandas) # 0619\n",
    "    s_label = df['second_party'].unique() \n",
    "\n",
    "    # 다른 사건임에도 같은 사람들이 중복돼서 등장함\n",
    "    print('다른 사건인데 중복되는 퍼스트 파티의 갯수 :',len(df['first_party'])-len(f_label))\n",
    "    print('다른 사건인데 중복되는 세컨드 파티의 갯수 :',len(df['second_party'])-len(s_label))\n",
    "\n",
    "    # 퍼스트와 세컨드 양쪽 모두 등장하는 사람들\n",
    "    intersection_label = set(f_label) & set(s_label) # set으로 만들어서 중복되는 지 체크 # 0619\n",
    "    print('퍼스트와 세컨드에서 모두 등장하는 사람들의 수 : ',len(intersection_label))\n",
    "    print('퍼스트와 세컨드에서 모두 등장하는 사람들 :',intersection_label)\n",
    "\n",
    "# jungbokCheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사건에서 언급이 안되는 퍼스트 파티의 수 : 405\n",
      "사건에서 언급이 안되는 세컨드 파티의 수 : 470\n",
      "사건에서 언급이 안되는 퍼스트와 세컨드의 수 : 82\n"
     ]
    }
   ],
   "source": [
    "# 팩트에 퍼스트파티와 세컨드파티가 포함 되어 있는지 확인하기\n",
    "\n",
    "df = train.drop(columns='ID')\n",
    "name_first_nofacts = []\n",
    "name_second_nofacts = []\n",
    "name_both_nofacts = []\n",
    "for i in range(df.shape[0]):\n",
    "    fact = df['facts'][i]\n",
    "    first = df['first_party'][i]\n",
    "    second = df['second_party'][i]\n",
    "    firstExist = True\n",
    "    secondExist = True\n",
    "    countBothNotExist = 0\n",
    "    splitNum_fir = len(first.split())\n",
    "    splitNum_sec = len(second.split())\n",
    "    for e in first.split():\n",
    "        if e in fact:\n",
    "            firstExist = True\n",
    "            break\n",
    "        else:\n",
    "            firstExist = False\n",
    "            splitNum_fir -= 1\n",
    "        if splitNum_fir <= 0:\n",
    "            countBothNotExist += 1\n",
    "            name_first_nofacts.append(i)\n",
    "    for e in second.split():\n",
    "        if e in fact:\n",
    "            secondExist = True\n",
    "            break\n",
    "        else:\n",
    "            secondExist = False\n",
    "            splitNum_sec -= 1\n",
    "        if splitNum_sec <= 0:\n",
    "            countBothNotExist += 1\n",
    "            name_second_nofacts.append(i)\n",
    "    if countBothNotExist == 2:\n",
    "        name_both_nofacts.append(i)\n",
    "\n",
    "print('사건에서 언급이 안되는 퍼스트 파티의 수 :',len(name_first_nofacts))\n",
    "print('사건에서 언급이 안되는 세컨드 파티의 수 :',len(name_second_nofacts))\n",
    "print('사건에서 언급이 안되는 퍼스트와 세컨드의 수 :',len(name_both_nofacts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 데이터셋 행의 갯수 : 2478\n",
      "양측 제거 후 행의 갯수 : 2396\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phil A. St. Amant</td>\n",
       "      <td>Herman A. Thompson</td>\n",
       "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stephen Duncan</td>\n",
       "      <td>Lawrence Owens</td>\n",
       "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Billy Joe Magwood</td>\n",
       "      <td>Tony Patterson, Warden, et al.</td>\n",
       "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linkletter</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Victor Linkletter was convicted in state court...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>William Earl Fikes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>HollyFrontier Cheyenne Refining, LLC, et al.</td>\n",
       "      <td>Renewable Fuels Association, et al.</td>\n",
       "      <td>Congress amended the Clean Air Act through the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>Grupo Mexicano de Desarrollo, S. A.</td>\n",
       "      <td>Alliance Bond Fund, Inc.</td>\n",
       "      <td>Alliance Bond Fund, Inc., an investment fund, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>Peguero</td>\n",
       "      <td>United States</td>\n",
       "      <td>In 1992, the District Court sentenced Manuel D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>Immigration and Naturalization Service</td>\n",
       "      <td>St. Cyr</td>\n",
       "      <td>On March 8, 1996, Enrico St. Cyr, a lawful per...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>Markman</td>\n",
       "      <td>Westview Instruments, Inc.</td>\n",
       "      <td>Herbert Markman owns the patent to a system th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2396 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       first_party  \\\n",
       "0                                Phil A. St. Amant   \n",
       "1                                   Stephen Duncan   \n",
       "2                                Billy Joe Magwood   \n",
       "3                                       Linkletter   \n",
       "4                               William Earl Fikes   \n",
       "...                                            ...   \n",
       "2473  HollyFrontier Cheyenne Refining, LLC, et al.   \n",
       "2474           Grupo Mexicano de Desarrollo, S. A.   \n",
       "2475                                       Peguero   \n",
       "2476        Immigration and Naturalization Service   \n",
       "2477                                       Markman   \n",
       "\n",
       "                             second_party  \\\n",
       "0                      Herman A. Thompson   \n",
       "1                          Lawrence Owens   \n",
       "2          Tony Patterson, Warden, et al.   \n",
       "3                                  Walker   \n",
       "4                                 Alabama   \n",
       "...                                   ...   \n",
       "2473  Renewable Fuels Association, et al.   \n",
       "2474             Alliance Bond Fund, Inc.   \n",
       "2475                        United States   \n",
       "2476                              St. Cyr   \n",
       "2477           Westview Instruments, Inc.   \n",
       "\n",
       "                                                  facts  first_party_winner  \n",
       "0     On June 27, 1962, Phil St. Amant, a candidate ...                   1  \n",
       "1     Ramon Nelson was riding his bike when he suffe...                   0  \n",
       "2     An Alabama state court convicted Billy Joe Mag...                   1  \n",
       "3     Victor Linkletter was convicted in state court...                   0  \n",
       "4     On April 24, 1953 in Selma, Alabama, an intrud...                   1  \n",
       "...                                                 ...                 ...  \n",
       "2473  Congress amended the Clean Air Act through the...                   1  \n",
       "2474  Alliance Bond Fund, Inc., an investment fund, ...                   1  \n",
       "2475  In 1992, the District Court sentenced Manuel D...                   0  \n",
       "2476  On March 8, 1996, Enrico St. Cyr, a lawful per...                   0  \n",
       "2477  Herbert Markman owns the patent to a system th...                   0  \n",
       "\n",
       "[2396 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사건에 언급이 안되는 당사자들 빼기\n",
    "\n",
    "def deleteParty(first=False, second=False, both=True):\n",
    "    \"\"\"\n",
    "        제외시킬 사람들. 양측 제거는 디폴트\n",
    "    \"\"\"\n",
    "    # 양측 모두 제거\n",
    "    deleted_df = df.copy()\n",
    "    print('원래 데이터셋 행의 갯수 :',len(df))\n",
    "    if both == True:\n",
    "        deleted_df = deleted_df.drop(index=name_both_nofacts)\n",
    "        print('양측 제거 후 행의 갯수 :',len(deleted_df))\n",
    "    # 퍼스트 제거\n",
    "    if first == True:\n",
    "        left_name_list = set(name_first_nofacts) - set(name_both_nofacts) # 차집합 # 0619\n",
    "        deleted_df = deleted_df.drop(index=left_name_list)\n",
    "        print('퍼스트파티 제거 후 갯수 :',len(deleted_df))\n",
    "    # 세컨드 제거\n",
    "    if second == True:\n",
    "        left_name_list = set(name_second_nofacts) - set(name_both_nofacts)\n",
    "        deleted_df = deleted_df.drop(index=left_name_list)\n",
    "        print('세컨드파티 후 갯수 :',len(deleted_df))\n",
    "    \n",
    "    return deleted_df\n",
    "\n",
    "name_deleted_df = deleteParty(first=False, second=False, both=True)\n",
    "name_deleted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 데이터갯수 : 1592\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phil A. St. Amant</td>\n",
       "      <td>Herman A. Thompson</td>\n",
       "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Billy Joe Magwood</td>\n",
       "      <td>Tony Patterson, Warden, et al.</td>\n",
       "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Earl Fikes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C &amp; A Carbone, Inc., et al.</td>\n",
       "      <td>Town of Clarkstown</td>\n",
       "      <td>A New York town, Clarkstown, allowed a contrac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Jennings, et al.</td>\n",
       "      <td>Alejandro Rodriguez, et al.</td>\n",
       "      <td>Sections of the Immigration and Nationality Ac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>Central Laborers' Pension Fund</td>\n",
       "      <td>Thomas E. Heinz, et al.</td>\n",
       "      <td>Thomas Heinz worked as a construction worker f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>United States</td>\n",
       "      <td>Cuauhtemoc Gonzalez-Lopez</td>\n",
       "      <td>Cuauhtemoc Gonzalez-Lopez hired Joseph Low, an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>Peguero</td>\n",
       "      <td>United States</td>\n",
       "      <td>In 1992, the District Court sentenced Manuel D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>Immigration and Naturalization Service</td>\n",
       "      <td>St. Cyr</td>\n",
       "      <td>On March 8, 1996, Enrico St. Cyr, a lawful per...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>Markman</td>\n",
       "      <td>Westview Instruments, Inc.</td>\n",
       "      <td>Herbert Markman owns the patent to a system th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 first_party                    second_party  \\\n",
       "0                          Phil A. St. Amant              Herman A. Thompson   \n",
       "1                          Billy Joe Magwood  Tony Patterson, Warden, et al.   \n",
       "2                         William Earl Fikes                         Alabama   \n",
       "3                C & A Carbone, Inc., et al.              Town of Clarkstown   \n",
       "4                     David Jennings, et al.     Alejandro Rodriguez, et al.   \n",
       "...                                      ...                             ...   \n",
       "1587          Central Laborers' Pension Fund         Thomas E. Heinz, et al.   \n",
       "1588                           United States       Cuauhtemoc Gonzalez-Lopez   \n",
       "1589                                 Peguero                   United States   \n",
       "1590  Immigration and Naturalization Service                         St. Cyr   \n",
       "1591                                 Markman      Westview Instruments, Inc.   \n",
       "\n",
       "                                                  facts  first_party_winner  \n",
       "0     On June 27, 1962, Phil St. Amant, a candidate ...                   1  \n",
       "1     An Alabama state court convicted Billy Joe Mag...                   1  \n",
       "2     On April 24, 1953 in Selma, Alabama, an intrud...                   1  \n",
       "3     A New York town, Clarkstown, allowed a contrac...                   1  \n",
       "4     Sections of the Immigration and Nationality Ac...                   1  \n",
       "...                                                 ...                 ...  \n",
       "1587  Thomas Heinz worked as a construction worker f...                   0  \n",
       "1588  Cuauhtemoc Gonzalez-Lopez hired Joseph Low, an...                   0  \n",
       "1589  In 1992, the District Court sentenced Manuel D...                   0  \n",
       "1590  On March 8, 1996, Enrico St. Cyr, a lawful per...                   0  \n",
       "1591  Herbert Markman owns the patent to a system th...                   0  \n",
       "\n",
       "[1592 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 승소와 패소 데이터 비율 5:5로 맞추기 # 0619\n",
    "\n",
    "# 승소와 패소 개수 각각 저장\n",
    "won_lost_value = name_deleted_df['first_party_winner'].value_counts()\n",
    "count1 = won_lost_value[1]\n",
    "count0 = won_lost_value[0]\n",
    "\n",
    "# 승소한 리스트 인덱스 0부터 다시 지정\n",
    "reindex_df1 = name_deleted_df[name_deleted_df['first_party_winner']==1]\n",
    "reindex_df1.reset_index(inplace=True, drop=True)\n",
    "# 패소한 리스트\n",
    "reindex_df0 = name_deleted_df[name_deleted_df['first_party_winner']==0]\n",
    "\n",
    "# 시드 정해놔서 항상 같은 숫자 나오도록 하기\n",
    "import random\n",
    "random.seed(0)\n",
    "remove_list = random.randint(0,count0)\n",
    "\n",
    "# 패소한 리스트의 갯수만큼 인덱스 랜덤으로 뽑기\n",
    "lst_1_index = random.sample(range(0,len(reindex_df1)),count0)\n",
    "lst_1_index.sort()\n",
    "lst_1_index\n",
    "\n",
    "# 랜덤인덱스에 맞는 승소 리스트 만들기 (패소리스트 갯수만큼)\n",
    "newone = reindex_df1.loc[reindex_df1.index.isin(lst_1_index)]\n",
    "\n",
    "# 승소리스트 패소리스트 합치기\n",
    "balanced_list = pd.concat([newone, reindex_df0])\n",
    "balanced_list.reset_index(inplace=True, drop=True)\n",
    "print('새로운 데이터갯수 :',len(balanced_list))\n",
    "balanced_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phil A. St. Amant</td>\n",
       "      <td>Herman A. Thompson</td>\n",
       "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Billy Joe Magwood</td>\n",
       "      <td>Tony Patterson, Warden, et al.</td>\n",
       "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Earl Fikes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C &amp; A Carbone, Inc., et al.</td>\n",
       "      <td>Town of Clarkstown</td>\n",
       "      <td>A New York town, Clarkstown, allowed a contrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Jennings, et al.</td>\n",
       "      <td>Alejandro Rodriguez, et al.</td>\n",
       "      <td>Sections of the Immigration and Nationality Ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>Central Laborers' Pension Fund</td>\n",
       "      <td>Thomas E. Heinz, et al.</td>\n",
       "      <td>Thomas Heinz worked as a construction worker f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>United States</td>\n",
       "      <td>Cuauhtemoc Gonzalez-Lopez</td>\n",
       "      <td>Cuauhtemoc Gonzalez-Lopez hired Joseph Low, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>Peguero</td>\n",
       "      <td>United States</td>\n",
       "      <td>In 1992, the District Court sentenced Manuel D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>Immigration and Naturalization Service</td>\n",
       "      <td>St. Cyr</td>\n",
       "      <td>On March 8, 1996, Enrico St. Cyr, a lawful per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>Markman</td>\n",
       "      <td>Westview Instruments, Inc.</td>\n",
       "      <td>Herbert Markman owns the patent to a system th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 first_party                    second_party  \\\n",
       "0                          Phil A. St. Amant              Herman A. Thompson   \n",
       "1                          Billy Joe Magwood  Tony Patterson, Warden, et al.   \n",
       "2                         William Earl Fikes                         Alabama   \n",
       "3                C & A Carbone, Inc., et al.              Town of Clarkstown   \n",
       "4                     David Jennings, et al.     Alejandro Rodriguez, et al.   \n",
       "...                                      ...                             ...   \n",
       "1587          Central Laborers' Pension Fund         Thomas E. Heinz, et al.   \n",
       "1588                           United States       Cuauhtemoc Gonzalez-Lopez   \n",
       "1589                                 Peguero                   United States   \n",
       "1590  Immigration and Naturalization Service                         St. Cyr   \n",
       "1591                                 Markman      Westview Instruments, Inc.   \n",
       "\n",
       "                                                  facts  \n",
       "0     On June 27, 1962, Phil St. Amant, a candidate ...  \n",
       "1     An Alabama state court convicted Billy Joe Mag...  \n",
       "2     On April 24, 1953 in Selma, Alabama, an intrud...  \n",
       "3     A New York town, Clarkstown, allowed a contrac...  \n",
       "4     Sections of the Immigration and Nationality Ac...  \n",
       "...                                                 ...  \n",
       "1587  Thomas Heinz worked as a construction worker f...  \n",
       "1588  Cuauhtemoc Gonzalez-Lopez hired Joseph Low, an...  \n",
       "1589  In 1992, the District Court sentenced Manuel D...  \n",
       "1590  On March 8, 1996, Enrico St. Cyr, a lawful per...  \n",
       "1591  Herbert Markman owns the patent to a system th...  \n",
       "\n",
       "[1592 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = balanced_list[['first_party_winner']]\n",
    "df_nlp1 = pd.DataFrame(balanced_list.drop(columns='first_party_winner'))\n",
    "df_nlp1['facts'] = df_nlp1['facts'].str.replace(r'<[^<>]*>', '', regex=True) # 특수 문자 제거\n",
    "# df_nlp1['facts'] = df_nlp1['facts'].str.replace(r'\\d', '', regex=True)  # 숫자 제거\n",
    "df_nlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_facts = df_nlp1['facts']\n",
    "lst_tokens_facts = nltk.tokenize.word_tokenize(corpus_facts.str.cat(sep=\" \"))\n",
    "\n",
    "ps = nltk.stem.porter.PorterStemmer()\n",
    "lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "lst_stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 깨끗하게 만드는 함수\n",
    "\n",
    "def utils_preprocess_text(text, flg_stemm=True, flg_lemm=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    import re\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list # 역토큰화, 벡터화 하기 위해서\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>facts_clean</th>\n",
       "      <th>first_clean</th>\n",
       "      <th>second_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phil A. St. Amant</td>\n",
       "      <td>Herman A. Thompson</td>\n",
       "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
       "      <td>june 27 1962 phil st amant candidate public of...</td>\n",
       "      <td>phil a st amant</td>\n",
       "      <td>herman a thompson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Billy Joe Magwood</td>\n",
       "      <td>Tony Patterson, Warden, et al.</td>\n",
       "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
       "      <td>alabama state court convicted billy joe magwoo...</td>\n",
       "      <td>billy joe magwood</td>\n",
       "      <td>tony patterson warden et al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Earl Fikes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
       "      <td>april 24 1953 selma alabama intruder broke apa...</td>\n",
       "      <td>william earl fikes</td>\n",
       "      <td>alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C &amp; A Carbone, Inc., et al.</td>\n",
       "      <td>Town of Clarkstown</td>\n",
       "      <td>A New York town, Clarkstown, allowed a contrac...</td>\n",
       "      <td>new york town clarkstown allowed contractor co...</td>\n",
       "      <td>c a carbone inc et al</td>\n",
       "      <td>town of clarkstown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Jennings, et al.</td>\n",
       "      <td>Alejandro Rodriguez, et al.</td>\n",
       "      <td>Sections of the Immigration and Nationality Ac...</td>\n",
       "      <td>section immigration nationality act require no...</td>\n",
       "      <td>david jennings et al</td>\n",
       "      <td>alejandro rodriguez et al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>Central Laborers' Pension Fund</td>\n",
       "      <td>Thomas E. Heinz, et al.</td>\n",
       "      <td>Thomas Heinz worked as a construction worker f...</td>\n",
       "      <td>thomas heinz worked construction worker 20 yea...</td>\n",
       "      <td>central laborers pension fund</td>\n",
       "      <td>thomas e heinz et al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>United States</td>\n",
       "      <td>Cuauhtemoc Gonzalez-Lopez</td>\n",
       "      <td>Cuauhtemoc Gonzalez-Lopez hired Joseph Low, an...</td>\n",
       "      <td>gonzalezlopez hired joseph low attorney repres...</td>\n",
       "      <td>united states</td>\n",
       "      <td>cuauhtemoc gonzalezlopez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>Peguero</td>\n",
       "      <td>United States</td>\n",
       "      <td>In 1992, the District Court sentenced Manuel D...</td>\n",
       "      <td>1992 district court sentenced manuel peguero 2...</td>\n",
       "      <td>peguero</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>Immigration and Naturalization Service</td>\n",
       "      <td>St. Cyr</td>\n",
       "      <td>On March 8, 1996, Enrico St. Cyr, a lawful per...</td>\n",
       "      <td>march 8 1996 st cyr lawful permanent resident ...</td>\n",
       "      <td>immigration and naturalization service</td>\n",
       "      <td>st cyr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>Markman</td>\n",
       "      <td>Westview Instruments, Inc.</td>\n",
       "      <td>Herbert Markman owns the patent to a system th...</td>\n",
       "      <td>herbert owns patent system track clothing dryc...</td>\n",
       "      <td>markman</td>\n",
       "      <td>westview instruments inc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 first_party                    second_party  \\\n",
       "0                          Phil A. St. Amant              Herman A. Thompson   \n",
       "1                          Billy Joe Magwood  Tony Patterson, Warden, et al.   \n",
       "2                         William Earl Fikes                         Alabama   \n",
       "3                C & A Carbone, Inc., et al.              Town of Clarkstown   \n",
       "4                     David Jennings, et al.     Alejandro Rodriguez, et al.   \n",
       "...                                      ...                             ...   \n",
       "1587          Central Laborers' Pension Fund         Thomas E. Heinz, et al.   \n",
       "1588                           United States       Cuauhtemoc Gonzalez-Lopez   \n",
       "1589                                 Peguero                   United States   \n",
       "1590  Immigration and Naturalization Service                         St. Cyr   \n",
       "1591                                 Markman      Westview Instruments, Inc.   \n",
       "\n",
       "                                                  facts  \\\n",
       "0     On June 27, 1962, Phil St. Amant, a candidate ...   \n",
       "1     An Alabama state court convicted Billy Joe Mag...   \n",
       "2     On April 24, 1953 in Selma, Alabama, an intrud...   \n",
       "3     A New York town, Clarkstown, allowed a contrac...   \n",
       "4     Sections of the Immigration and Nationality Ac...   \n",
       "...                                                 ...   \n",
       "1587  Thomas Heinz worked as a construction worker f...   \n",
       "1588  Cuauhtemoc Gonzalez-Lopez hired Joseph Low, an...   \n",
       "1589  In 1992, the District Court sentenced Manuel D...   \n",
       "1590  On March 8, 1996, Enrico St. Cyr, a lawful per...   \n",
       "1591  Herbert Markman owns the patent to a system th...   \n",
       "\n",
       "                                            facts_clean  \\\n",
       "0     june 27 1962 phil st amant candidate public of...   \n",
       "1     alabama state court convicted billy joe magwoo...   \n",
       "2     april 24 1953 selma alabama intruder broke apa...   \n",
       "3     new york town clarkstown allowed contractor co...   \n",
       "4     section immigration nationality act require no...   \n",
       "...                                                 ...   \n",
       "1587  thomas heinz worked construction worker 20 yea...   \n",
       "1588  gonzalezlopez hired joseph low attorney repres...   \n",
       "1589  1992 district court sentenced manuel peguero 2...   \n",
       "1590  march 8 1996 st cyr lawful permanent resident ...   \n",
       "1591  herbert owns patent system track clothing dryc...   \n",
       "\n",
       "                                 first_clean                 second_clean  \n",
       "0                            phil a st amant            herman a thompson  \n",
       "1                          billy joe magwood  tony patterson warden et al  \n",
       "2                         william earl fikes                      alabama  \n",
       "3                      c a carbone inc et al           town of clarkstown  \n",
       "4                       david jennings et al    alejandro rodriguez et al  \n",
       "...                                      ...                          ...  \n",
       "1587           central laborers pension fund         thomas e heinz et al  \n",
       "1588                           united states     cuauhtemoc gonzalezlopez  \n",
       "1589                                 peguero                united states  \n",
       "1590  immigration and naturalization service                       st cyr  \n",
       "1591                                 markman     westview instruments inc  \n",
       "\n",
       "[1592 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 깨끗하게 만드는 함수 사용\n",
    "df_nlp1[\"facts_clean\"] = df_nlp1[\"facts\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=lst_stopwords))\n",
    "df_nlp1[\"first_clean\"] = df_nlp1[\"first_party\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=False))\n",
    "df_nlp1[\"second_clean\"] = df_nlp1[\"second_party\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=False))\n",
    "\n",
    "# 갯수가 하나만 있는 단어들 제거\n",
    "corpus_stopwords = df_nlp1[\"facts_clean\"]\n",
    "lst_tokens_stopwords = nltk.tokenize.word_tokenize(corpus_stopwords.str.cat(sep=\" \"))\n",
    "stop_words=[]\n",
    "\n",
    "for word, freq in nltk.FreqDist(lst_tokens_stopwords).most_common():\n",
    "    if freq == 1:\n",
    "        #print(word)\n",
    "        stop_words.append(word)\n",
    "\n",
    "df_nlp1[\"facts_clean\"] = df_nlp1[\"facts_clean\"] .apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=False, lst_stopwords=stop_words))\n",
    "\n",
    "df_nlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facts_clean</th>\n",
       "      <th>first_clean</th>\n",
       "      <th>second_clean</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>june 27 1962 phil st amant candidate public of...</td>\n",
       "      <td>phil a st amant</td>\n",
       "      <td>herman a thompson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alabama state court convicted billy joe magwoo...</td>\n",
       "      <td>billy joe magwood</td>\n",
       "      <td>tony patterson warden et al</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>april 24 1953 selma alabama intruder broke apa...</td>\n",
       "      <td>william earl fikes</td>\n",
       "      <td>alabama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new york town clarkstown allowed contractor co...</td>\n",
       "      <td>c a carbone inc et al</td>\n",
       "      <td>town of clarkstown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>section immigration nationality act require no...</td>\n",
       "      <td>david jennings et al</td>\n",
       "      <td>alejandro rodriguez et al</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>thomas heinz worked construction worker 20 yea...</td>\n",
       "      <td>central laborers pension fund</td>\n",
       "      <td>thomas e heinz et al</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>gonzalezlopez hired joseph low attorney repres...</td>\n",
       "      <td>united states</td>\n",
       "      <td>cuauhtemoc gonzalezlopez</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>1992 district court sentenced manuel peguero 2...</td>\n",
       "      <td>peguero</td>\n",
       "      <td>united states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>march 8 1996 st cyr lawful permanent resident ...</td>\n",
       "      <td>immigration and naturalization service</td>\n",
       "      <td>st cyr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>herbert owns patent system track clothing dryc...</td>\n",
       "      <td>markman</td>\n",
       "      <td>westview instruments inc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1592 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            facts_clean  \\\n",
       "0     june 27 1962 phil st amant candidate public of...   \n",
       "1     alabama state court convicted billy joe magwoo...   \n",
       "2     april 24 1953 selma alabama intruder broke apa...   \n",
       "3     new york town clarkstown allowed contractor co...   \n",
       "4     section immigration nationality act require no...   \n",
       "...                                                 ...   \n",
       "1587  thomas heinz worked construction worker 20 yea...   \n",
       "1588  gonzalezlopez hired joseph low attorney repres...   \n",
       "1589  1992 district court sentenced manuel peguero 2...   \n",
       "1590  march 8 1996 st cyr lawful permanent resident ...   \n",
       "1591  herbert owns patent system track clothing dryc...   \n",
       "\n",
       "                                 first_clean                 second_clean  \\\n",
       "0                            phil a st amant            herman a thompson   \n",
       "1                          billy joe magwood  tony patterson warden et al   \n",
       "2                         william earl fikes                      alabama   \n",
       "3                      c a carbone inc et al           town of clarkstown   \n",
       "4                       david jennings et al    alejandro rodriguez et al   \n",
       "...                                      ...                          ...   \n",
       "1587           central laborers pension fund         thomas e heinz et al   \n",
       "1588                           united states     cuauhtemoc gonzalezlopez   \n",
       "1589                                 peguero                united states   \n",
       "1590  immigration and naturalization service                       st cyr   \n",
       "1591                                 markman     westview instruments inc   \n",
       "\n",
       "      first_party_winner  \n",
       "0                      1  \n",
       "1                      1  \n",
       "2                      1  \n",
       "3                      1  \n",
       "4                      1  \n",
       "...                  ...  \n",
       "1587                   0  \n",
       "1588                   0  \n",
       "1589                   0  \n",
       "1590                   0  \n",
       "1591                   0  \n",
       "\n",
       "[1592 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델링 전 완전 데이터\n",
    "df_nlp2 = pd.concat([df_nlp1['facts_clean'],df_nlp1['first_clean'],df_nlp1['second_clean'],df_target['first_party_winner']],axis=1, join='inner')\n",
    "# df_nlp2 = pd.concat([df_nlp1['facts_clean'],df_nlp1['first_party'],df_nlp1['second_party'],df_target['first_party_winner']],axis=1, join='inner')\n",
    "df_nlp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF / 전체 문서들 중에서 빈도수가 높으면 가중치가 낮고, 특정 문서에서 빈도수가 높으면 가중치를 높게 줌\n",
    "\n",
    "# vectorizeTF = TfidfVectorizer()\n",
    "# count_matrix_tf = vectorizeTF.fit_transform(df_nlp2['facts_clean'])\n",
    "# data_final = count_matrix_tf.toarray()\n",
    "# data_final = pd.DataFrame(data=data_final, columns=vectorizeTF.get_feature_names_out())\n",
    "# data_final = pd.concat([data_final,df_nlp2[\"first_party_winner\"]],axis=1,join='inner')\n",
    "# terms = vectorizeTF.get_feature_names_out()\n",
    "# data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카운터 벡터라이즈 / 전체 문서에서 빈도수가 높으면 가중치가 높음\n",
    "   \n",
    "# vectorizeCV=CountVectorizer()\n",
    "# count_matrix = vectorizeCV.fit_transform(df_nlp2['facts_clean'])\n",
    "# count_array = count_matrix.toarray()\n",
    "# data_final = pd.DataFrame(data=count_array,columns = vectorizeCV.get_feature_names_out())\n",
    "# data_final = pd.concat([data_final,df_nlp2[\"first_party_winner\"]],axis=1,join='inner')\n",
    "# terms = vectorizeCV.get_feature_names_out()\n",
    "# data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseVec(vec,nlp,testSet=False):\n",
    "    \"\"\"\n",
    "        벡터 고르는 함수입니다.\n",
    "        vec 파라미터로 tf-idf이면 'tf', count-vector는 'cv'.\n",
    "        nlp는 깨끗하게 전처리된 데이터셋을 보내주세요.\n",
    "    \"\"\"\n",
    "    global terms, vectorize\n",
    "\n",
    "    if testSet == True: # 테스트 셋일 경우, 새로운 인스턴스를 부여하면 안되니까\n",
    "        count_matrix = vectorize.transform(nlp['facts_clean'])\n",
    "    \n",
    "    if vec == 'tf' and testSet == False:\n",
    "        #TFIDF / 전체 문서들 중에서 빈도수가 높으면 가중치가 낮고, 특정 문서에서 빈도수가 높으면 가중치를 높게 줌\n",
    "        vectorize = TfidfVectorizer()\n",
    "        count_matrix = vectorize.fit_transform(nlp['facts_clean'])\n",
    "\n",
    "    if vec == 'cv'and testSet == False:\n",
    "        # 카운터 벡터라이즈 / 전체 문서에서 빈도수가 높으면 가중치가 높음\n",
    "        vectorize=CountVectorizer()\n",
    "        count_matrix = vectorize.fit_transform(nlp['facts_clean'])\n",
    "\n",
    "    count_array = count_matrix.toarray()\n",
    "    data_final = pd.DataFrame(data=count_array,columns = vectorize.get_feature_names_out())\n",
    "    data_final = pd.concat([data_final,nlp[\"first_party_winner\"]],axis=1,join='inner')\n",
    "    terms = vectorize.get_feature_names_out()\n",
    "    testSet = False\n",
    "    return data_final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = chooseVec('tf', df_nlp2) # td-idf : 'tf' / counter vector : 'cv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(data_final.drop(columns=['first_party_winner']), data_final['first_party_winner'], test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import LatentDirichletAllocation\n",
    "# lda = LatentDirichletAllocation(n_components=200, random_state=1) # n_component : 토픽 갯수\n",
    "# pd.DataFrame(lda.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 쪼개기\n",
    "def splitData(data):\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['first_party_winner']), data['first_party_winner'], test_size=0.3,random_state=0)\n",
    "\n",
    "# LDA 학습\n",
    "# def ldaTraining(data, n):\n",
    "#     \"\"\"\n",
    "#         X_trian과 lDA 적용 후 확인할 데이터 n개\n",
    "#     \"\"\"\n",
    "#     # LDA 학습, 단어의 의미구조 파악\n",
    "#     # 30초정도 걸림\n",
    "#     global lda, X_train\n",
    "#     from sklearn.decomposition import LatentDirichletAllocation\n",
    "#     lda = LatentDirichletAllocation(n_components=200, random_state=1) # n_component : 토픽 갯수\n",
    "#     lda_data = lda.fit_transform(data)\n",
    "#     X_train = pd.DataFrame(data=lda_data)\n",
    "#     # LDA 학습 결과 보기\n",
    "#     for idx, topic in enumerate(lda.components_):\n",
    "#         print(\"Topic %d:\" % (idx+1), [(terms[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "\n",
    "\n",
    "# 모델 만들기\n",
    "def modeling(params):\n",
    "    \"\"\"\n",
    "        XGB 학습 모델 함수.\n",
    "        XGB 파라미터를 받습니다.\n",
    "    \"\"\"\n",
    "    global model\n",
    "    # model = XGBClassifier(**params) # **param_dict\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.get_params())\n",
    "\n",
    "# 예측하기\n",
    "def prediction(data):\n",
    "    \"\"\"\n",
    "        테스트 데이터 예측하기\n",
    "    \"\"\"\n",
    "    # lda_data_t = pd.DataFrame(data=lda.transform(data)) # 테스트 lda 적용\n",
    "    y_pred = model.predict(data)\n",
    "    y_pred_df = pd.DataFrame(data=y_pred, columns=['data'])\n",
    "    display(y_pred_df.value_counts())\n",
    "\n",
    "    # 평가\n",
    "    from sklearn.metrics import f1_score\n",
    "    accuracy = accuracy_score(y_test, y_pred) # 정확도\n",
    "    print(\"Accuracy : %.2f%%\" % (accuracy * 100.0)) \n",
    "    print('f1_score :', f1_score(y_test, y_pred)) # 정밀도와 재현율의 조화평균\n",
    "    print(\"model accuracy score (X_train, y_train):\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'binary:logistic', 'use_label_encoder': None, 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'predictor': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "def fullTraining(data):\n",
    "    # 훈련\n",
    "    splitData(data)\n",
    "    # ldaTraining(X_train, 5)\n",
    "\n",
    "    # XG부스트 모델 적용하기\n",
    "    default_gs_params =  {'learning_rate': 0.9, 'max_depth': 9, 'subsample': 0.5}\n",
    "    modeling(default_gs_params)\n",
    "\n",
    "fullTraining(data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data\n",
       "1       259\n",
       "0       219\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 51.05%\n",
      "f1_score : 0.5301204819277109\n",
      "model accuracy score (X_train, y_train): 0.5104602510460251\n"
     ]
    }
   ],
   "source": [
    "# 테스트 적용\n",
    "prediction(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6976948 , 0.30230525],\n",
       "       [0.64265704, 0.357343  ],\n",
       "       [0.6362013 , 0.36379868],\n",
       "       ...,\n",
       "       [0.08203512, 0.9179649 ],\n",
       "       [0.7457112 , 0.25428876],\n",
       "       [0.05382466, 0.94617534]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드서치로 최적의 파라미터 값 찾아보기\n",
    "\n",
    "def findParam():\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    param_xgb = {\n",
    "                 \"learning_rate\":[0.3, 0.6, 0.9], # 0~1 높을 수록 과적합 된다, 만약에 값이 낮으면 n_estimators를 높여야 과적합이 방지\n",
    "                 \"max_depth\":[3,5,7,9], # 보통 3~10, 높을 수록 과적합\n",
    "                 \"subsample\":[0.5, 0.7, 0.9] # 학습에 사용하는 샘플링 비율 0.5 ~ 1, 높을 수록 과적합\n",
    "                }    \n",
    "\n",
    "    gscv_xgb = GridSearchCV (estimator = model, param_grid = param_xgb, scoring ='accuracy', cv = 3, refit=True, n_jobs=1, verbose=2)\n",
    "    gscv_xgb.fit(X_train, y_train)\n",
    "    gs_params= gscv_xgb.best_params_\n",
    "    print('XGB 파라미터: ', gs_params)\n",
    "    print('XGB 예측 정확도: {:.4f}'.format(gscv_xgb.best_score_))\n",
    "\n",
    "    return gs_params\n",
    "# 그리드서치 후 파라미터 적용해서 모델링 학습 다시 하기\n",
    "# modeling(findParam())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트csv 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>Salerno</td>\n",
       "      <td>United States</td>\n",
       "      <td>The 1984 Bail Reform Act allowed the federal c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>Milberg Weiss Bershad Hynes and Lerach</td>\n",
       "      <td>Lexecon, Inc.</td>\n",
       "      <td>Lexecon Inc. was a defendant in a class action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>No. 07-582\\t Title: \\t Federal Communications ...</td>\n",
       "      <td>Fox Television Stations, Inc., et al.</td>\n",
       "      <td>In 2002 and 2003, Fox Television Stations broa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>Harold Kaufman</td>\n",
       "      <td>United States</td>\n",
       "      <td>During his trial for armed robbery of a federa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>Berger</td>\n",
       "      <td>Hanlon</td>\n",
       "      <td>In 1993, a magistrate judge issued a warrant a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>TEST_1235</td>\n",
       "      <td>Haitian Centers Council, Inc., et al.</td>\n",
       "      <td>Chris Sale, Acting Commissioner, Immigration A...</td>\n",
       "      <td>According to Executive Order No. 12807 signed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>TEST_1236</td>\n",
       "      <td>Whitman</td>\n",
       "      <td>American Trucking Associations, Inc.</td>\n",
       "      <td>Section 109(a) of the Clean Air Act (CAA) requ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>TEST_1237</td>\n",
       "      <td>Linda A. Matteo and John J. Madigan</td>\n",
       "      <td>William G. Barr</td>\n",
       "      <td>Linda Matteo and John Madigan created a plan f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>TEST_1238</td>\n",
       "      <td>Washington State Apple Advertising Commission</td>\n",
       "      <td>Hunt</td>\n",
       "      <td>In 1972, the North Carolina Board of Agricultu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>TEST_1239</td>\n",
       "      <td>Theodore Stovall</td>\n",
       "      <td>Wilfred Denno, Warden</td>\n",
       "      <td>On August 23, 1961, Dr. Paul Berheldt was stab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                        first_party  \\\n",
       "0     TEST_0000                                            Salerno   \n",
       "1     TEST_0001             Milberg Weiss Bershad Hynes and Lerach   \n",
       "2     TEST_0002  No. 07-582\\t Title: \\t Federal Communications ...   \n",
       "3     TEST_0003                                    Harold Kaufman    \n",
       "4     TEST_0004                                             Berger   \n",
       "...         ...                                                ...   \n",
       "1235  TEST_1235              Haitian Centers Council, Inc., et al.   \n",
       "1236  TEST_1236                                            Whitman   \n",
       "1237  TEST_1237                Linda A. Matteo and John J. Madigan   \n",
       "1238  TEST_1238      Washington State Apple Advertising Commission   \n",
       "1239  TEST_1239                                   Theodore Stovall   \n",
       "\n",
       "                                           second_party  \\\n",
       "0                                         United States   \n",
       "1                                         Lexecon, Inc.   \n",
       "2                 Fox Television Stations, Inc., et al.   \n",
       "3                                         United States   \n",
       "4                                                Hanlon   \n",
       "...                                                 ...   \n",
       "1235  Chris Sale, Acting Commissioner, Immigration A...   \n",
       "1236               American Trucking Associations, Inc.   \n",
       "1237                                    William G. Barr   \n",
       "1238                                               Hunt   \n",
       "1239                              Wilfred Denno, Warden   \n",
       "\n",
       "                                                  facts  \n",
       "0     The 1984 Bail Reform Act allowed the federal c...  \n",
       "1     Lexecon Inc. was a defendant in a class action...  \n",
       "2     In 2002 and 2003, Fox Television Stations broa...  \n",
       "3     During his trial for armed robbery of a federa...  \n",
       "4     In 1993, a magistrate judge issued a warrant a...  \n",
       "...                                                 ...  \n",
       "1235  According to Executive Order No. 12807 signed ...  \n",
       "1236  Section 109(a) of the Clean Air Act (CAA) requ...  \n",
       "1237  Linda Matteo and John Madigan created a plan f...  \n",
       "1238  In 1972, the North Carolina Board of Agricultu...  \n",
       "1239  On August 23, 1961, Dr. Paul Berheldt was stab...  \n",
       "\n",
       "[1240 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.DataFrame(data=test).drop(columns=['ID'])\n",
    "dfTest['facts'] = dfTest['facts'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "dfTest[\"facts_clean\"] = dfTest[\"facts\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=lst_stopwords))\n",
    "dfTest[\"first_clean\"] = dfTest[\"first_party\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=False))\n",
    "dfTest[\"second_clean\"] = dfTest[\"second_party\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=False))\n",
    "\n",
    "# 갯수가 하나만 있는 단어들 제거\n",
    "corpus_stopwords = dfTest[\"facts_clean\"]\n",
    "lst_tokens_stopwords = nltk.tokenize.word_tokenize(corpus_stopwords.str.cat(sep=\" \"))\n",
    "stop_words=[]\n",
    "\n",
    "for word, freq in nltk.FreqDist(lst_tokens_stopwords).most_common():\n",
    "    if freq == 1:\n",
    "        #print(word)\n",
    "        stop_words.append(word)\n",
    "\n",
    "dfTest[\"facts_clean\"] = dfTest[\"facts_clean\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=False, lst_stopwords=stop_words))\n",
    "\n",
    "dfTest['first_party_winner'] = np.zeros(len(dfTest)).astype(int)\n",
    "dfTest = dfTest.drop(columns=['facts','first_party','second_party'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facts_clean</th>\n",
       "      <th>first_clean</th>\n",
       "      <th>second_clean</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984 bail reform act allowed federal court det...</td>\n",
       "      <td>salerno</td>\n",
       "      <td>united states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lexecon inc defendant class action lawsuit 28 ...</td>\n",
       "      <td>milberg weiss bershad hynes and lerach</td>\n",
       "      <td>lexecon inc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002 2003 fox television station broadcast bil...</td>\n",
       "      <td>no 07582 title federal communications commissi...</td>\n",
       "      <td>fox television stations inc et al</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trial armed robbery federally insured saving l...</td>\n",
       "      <td>harold kaufman</td>\n",
       "      <td>united states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993 magistrate judge issued warrant authorizi...</td>\n",
       "      <td>berger</td>\n",
       "      <td>hanlon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>according executive order 12807 signed preside...</td>\n",
       "      <td>haitian centers council inc et al</td>\n",
       "      <td>chris sale acting commissioner immigration and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>section 109a clean air act caa requires enviro...</td>\n",
       "      <td>whitman</td>\n",
       "      <td>american trucking associations inc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>linda matteo john madigan created plan utilizi...</td>\n",
       "      <td>linda a matteo and john j madigan</td>\n",
       "      <td>william g barr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>1972 north carolina board agriculture adopted ...</td>\n",
       "      <td>washington state apple advertising commission</td>\n",
       "      <td>hunt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>august 23 1961 dr paul berheldt stabbed death ...</td>\n",
       "      <td>theodore stovall</td>\n",
       "      <td>wilfred denno warden</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            facts_clean  \\\n",
       "0     1984 bail reform act allowed federal court det...   \n",
       "1     lexecon inc defendant class action lawsuit 28 ...   \n",
       "2     2002 2003 fox television station broadcast bil...   \n",
       "3     trial armed robbery federally insured saving l...   \n",
       "4     1993 magistrate judge issued warrant authorizi...   \n",
       "...                                                 ...   \n",
       "1235  according executive order 12807 signed preside...   \n",
       "1236  section 109a clean air act caa requires enviro...   \n",
       "1237  linda matteo john madigan created plan utilizi...   \n",
       "1238  1972 north carolina board agriculture adopted ...   \n",
       "1239  august 23 1961 dr paul berheldt stabbed death ...   \n",
       "\n",
       "                                            first_clean  \\\n",
       "0                                               salerno   \n",
       "1                milberg weiss bershad hynes and lerach   \n",
       "2     no 07582 title federal communications commissi...   \n",
       "3                                        harold kaufman   \n",
       "4                                                berger   \n",
       "...                                                 ...   \n",
       "1235                  haitian centers council inc et al   \n",
       "1236                                            whitman   \n",
       "1237                  linda a matteo and john j madigan   \n",
       "1238      washington state apple advertising commission   \n",
       "1239                                   theodore stovall   \n",
       "\n",
       "                                           second_clean  first_party_winner  \n",
       "0                                         united states                   0  \n",
       "1                                           lexecon inc                   0  \n",
       "2                     fox television stations inc et al                   0  \n",
       "3                                         united states                   0  \n",
       "4                                                hanlon                   0  \n",
       "...                                                 ...                 ...  \n",
       "1235  chris sale acting commissioner immigration and...                   0  \n",
       "1236                 american trucking associations inc                   0  \n",
       "1237                                     william g barr                   0  \n",
       "1238                                               hunt                   0  \n",
       "1239                               wilfred denno warden                   0  \n",
       "\n",
       "[1240 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>06</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>100000</th>\n",
       "      <th>100to1</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>106</th>\n",
       "      <th>...</th>\n",
       "      <th>zita</th>\n",
       "      <th>zivotofsky</th>\n",
       "      <th>zivotofskys</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoneofinterests</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zuni</th>\n",
       "      <th>zurko</th>\n",
       "      <th>zurkos</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 8961 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       06   10  100  1000  10000  100000  100to1  101  102  106  ...  zita  \\\n",
       "0     0.0  0.0  0.0   0.0    0.0     0.0     0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1     0.0  0.0  0.0   0.0    0.0     0.0     0.0  0.0  0.0  0.0  ...   0.0   \n",
       "2     0.0  0.0  0.0   0.0    0.0     0.0     0.0  0.0  0.0  0.0  ...   0.0   \n",
       "3     0.0  0.0  0.0   0.0    0.0     0.0     0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4     0.0  0.0  0.0   0.0    0.0     0.0     0.0  0.0  0.0  0.0  ...   0.0   \n",
       "...   ...  ...  ...   ...    ...     ...     ...  ...  ...  ...  ...   ...   \n",
       "1235  0.0  0.0  0.0   0.0    0.0     0.0     0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1236  0.0  0.0  0.0   0.0    0.0     0.0     0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1237  0.0  0.0  0.0   0.0    0.0     0.0     0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1238  0.0  0.0  0.0   0.0    0.0     0.0     0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1239  0.0  0.0  0.0   0.0    0.0     0.0     0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "      zivotofsky  zivotofskys  zone  zoneofinterests  zoning  zuni  zurko  \\\n",
       "0            0.0          0.0   0.0              0.0     0.0   0.0    0.0   \n",
       "1            0.0          0.0   0.0              0.0     0.0   0.0    0.0   \n",
       "2            0.0          0.0   0.0              0.0     0.0   0.0    0.0   \n",
       "3            0.0          0.0   0.0              0.0     0.0   0.0    0.0   \n",
       "4            0.0          0.0   0.0              0.0     0.0   0.0    0.0   \n",
       "...          ...          ...   ...              ...     ...   ...    ...   \n",
       "1235         0.0          0.0   0.0              0.0     0.0   0.0    0.0   \n",
       "1236         0.0          0.0   0.0              0.0     0.0   0.0    0.0   \n",
       "1237         0.0          0.0   0.0              0.0     0.0   0.0    0.0   \n",
       "1238         0.0          0.0   0.0              0.0     0.0   0.0    0.0   \n",
       "1239         0.0          0.0   0.0              0.0     0.0   0.0    0.0   \n",
       "\n",
       "      zurkos  first_party_winner  \n",
       "0        0.0                   0  \n",
       "1        0.0                   0  \n",
       "2        0.0                   0  \n",
       "3        0.0                   0  \n",
       "4        0.0                   0  \n",
       "...      ...                 ...  \n",
       "1235     0.0                   0  \n",
       "1236     0.0                   0  \n",
       "1237     0.0                   0  \n",
       "1238     0.0                   0  \n",
       "1239     0.0                   0  \n",
       "\n",
       "[1240 rows x 8961 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 벡터 고르기\n",
    "data_final_test = chooseVec('tf', dfTest, True)\n",
    "data_final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitData(data_final_test)\n",
    "def testSplit(data):\n",
    "    global X_test, y_test\n",
    "    X_test = data.drop(columns=['first_party_winner'])\n",
    "    y_test = data['first_party_winner']\n",
    "testSplit(data_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testPredict():\n",
    "    global predcsv, X_test\n",
    "    \n",
    "    # X_test = dataTest.drop(columns=['first_party_winner'])\n",
    "    # y_test = dataTest['first_party_winner']\n",
    "    # X_test = pd.DataFrame(data=lda.transform(X_test))\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    predcsv = pd.DataFrame(y_pred_test, columns=['first_party_winner'])\n",
    "\n",
    "testPredict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission():\n",
    "    submit = pd.read_csv('C:/data/project/sample_submission.csv')\n",
    "    submit['first_party_winner'] = predcsv\n",
    "    submit.to_csv('./sample_submission.csv', index=False)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_party_winner\n",
       "1                     644\n",
       "0                     596\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predcsv.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "submission()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀프 트레이닝"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def findGoodSample():\n",
    "    # 데이터 준비\n",
    "    proba = model.predict_proba(X_test)\n",
    "    proba_df = pd.DataFrame(data=proba, columns=['proba_0','proba_1'])\n",
    "\n",
    "    # 0보다 1의 확률이 높은 데이터 추출\n",
    "    proba_higher = proba_df[proba_df['proba_1'] > proba_df['proba_0']]\n",
    "    # 1이 될 확률이 90프로 이상인 자료의 인덱스\n",
    "    proba_higher_index = proba_higher[proba_higher['proba_1'] > 0.9].index.to_list()\n",
    "\n",
    "    print('추가되는 샘플 갯수 :',len(proba_higher_index))\n",
    "    display(proba_higher_index)\n",
    "    # 인덱스 번호 리턴\n",
    "    return proba_higher_index\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dfTest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def concatSample():\n",
    "    newIdx = findGoodSample()\n",
    "    filtered = dfTest.loc[dfTest.index.isin(newIdx)].drop(columns='facts')\n",
    "    filtered['first_party_winner'] = 1\n",
    "    dataTest = pd.concat([df_nlp2,filtered]).reset_index(drop=True)\n",
    "    print('기존 샘플 갯수 :', len(df_nlp2))\n",
    "    print('새로운 프레임 데이터 갯수 :', len(dataTest))\n",
    "    return dataTest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_final_test = chooseVec('tf', concatSample(), True)\n",
    "fullTraining(data_final_test)\n",
    "prediction(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testPredict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predcsv.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
